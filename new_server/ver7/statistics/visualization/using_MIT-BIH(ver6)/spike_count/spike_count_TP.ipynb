{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-SNE 플롯 찍기용 (TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 변수\n",
    "checkpoint_dir = \"/home/hschoi/data/leehyunwon/ECG-SNN/ver6/SNN_MLP_ver6_TP_original_2024-12-27-14-32-47_fold1_lastEpoch.pt\"\n",
    "config_json_dir = \"/home/hschoi/data/leehyunwon/ECG-SNN/ver6/SNN_MLP_ver6_TP_original_2024-12-27-14-32-47_fold1_config.json\"\n",
    "\n",
    "savefile_name = \"T-SNE_TP.svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 10:18:43.004800: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-02 10:18:43.056689: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-02 10:18:43.946185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np # .npy 읽기용\n",
    "import pandas as pd # csv 읽기용\n",
    "import torch.nn.functional as F  # 일부 활성화 함수 등 파라미터 없는 함수에 사용\n",
    "import torchvision.datasets as datasets  # 일반적인 데이터셋; 이거 아마 MIT-BIH로 바꿔야 할 듯?\n",
    "import torchvision.transforms as transforms  # 데이터 증강을 위한 일종의 변형작업이라 함\n",
    "from torch import optim  # SGD, Adam 등의 옵티마이저(그래디언트는 이쪽으로 가면 됩니다)\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR # 코사인스케줄러(옵티마이저 보조용)\n",
    "from torch import nn  # 모든 DNN 모델들\n",
    "from torch.utils.data import (DataLoader, Dataset)  # 미니배치 등의 데이터셋 관리를 도와주는 녀석\n",
    "from tqdm import tqdm  # 진행도 표시용\n",
    "import torchmetrics # 평가지표 로깅용\n",
    "from typing import Callable # 람다식\n",
    "from torch.utils.tensorboard import SummaryWriter # tensorboard 기록용\n",
    "import time # 텐서보드 폴더명에 쓸 시각정보 기록용\n",
    "import random # 랜덤시드 고정용\n",
    "\n",
    "# 여긴 인코더 넣을때 혹시 몰라서 집어넣었음\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 얘는 SNN 학습이니까 당연히 있어야겠지? 특히 SNN 모델을 따로 만드려는 경우엔 뉴런 말고도 넣을 것이 많다.\n",
    "# import spikingjelly.activation_based as jelly\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, surrogate, layer\n",
    "\n",
    "from sklearn.model_selection import KFold # cross-validation용\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json파일 읽기 성공!\n",
      "Device :cuda\n"
     ]
    }
   ],
   "source": [
    "# 환경설정\n",
    "with open(config_json_dir, 'r') as f:\n",
    "    print(\"config.json파일 읽기 성공!\")\n",
    "    json_data = json.load(f)\n",
    "\n",
    "cuda_gpu = json_data['cuda_gpu']\n",
    "model_name = json_data['model_name']\n",
    "num_classes = json_data['num_classes']\n",
    "num_encoders = json_data['num_encoders']\n",
    "early_stop = json_data['early_stop']\n",
    "early_stop_enable = json_data['early_stop_enable']\n",
    "learning_rate = json_data['init_lr']\n",
    "batch_size = json_data['batch_size']\n",
    "num_epochs = json_data['num_epochs']\n",
    "train_path = json_data['train_path']\n",
    "test_path = json_data['test_path']\n",
    "class_weight = json_data['class_weight']\n",
    "encoder_min = json_data['encoder_min']\n",
    "encoder_max = json_data['encoder_max']\n",
    "hidden_size = json_data['hidden_size']\n",
    "hidden_size_2 = json_data['hidden_size_2']\n",
    "scheduler_tmax = json_data['scheduler_tmax']\n",
    "scheduler_eta_min = json_data['scheduler_eta_min']\n",
    "encoder_requires_grad = json_data['encoder_requires_grad']\n",
    "encoder_type = json_data['encoder_type']\n",
    "encoder_tp_iter_repeat = json_data['encoder_tp_iter_repeat']\n",
    "random_seed = json_data['random_seed']\n",
    "checkpoint_save = json_data['checkpoint_save']\n",
    "checkpoint_path = json_data['checkpoint_path']\n",
    "threshold_value = json_data['threshold_value']\n",
    "reset_value_residual = json_data['reset_value_residual']\n",
    "need_bias = json_data['need_bias']\n",
    "k_folds = json_data['k_folds']\n",
    "\n",
    "# Cuda 써야겠지?\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # GPU 번호별로 0번부터 나열\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= str(cuda_gpu)  # 상황에 맞춰 변경할 것\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # 연산에 GPU 쓰도록 지정\n",
    "print(\"Device :\" + device) # 확인용\n",
    "# input() # 일시정지용\n",
    "\n",
    "# 랜덤시드 고정\n",
    "seed = random_seed\n",
    "deterministic = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "      \n",
    "\n",
    "# TP 클래스\n",
    "class SNN_MLP(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size, hidden_size_2, threshold_value, bias_option, reset_value_residual):\n",
    "        super().__init__()\n",
    "        \n",
    "        # SNN 인코더 : 채널 크기만큼 확장하기\n",
    "        self.encoder = nn.Sequential(\n",
    "            # layer.Flatten(),\n",
    "            layer.Linear(1, hidden_size, bias=bias_option), # bias는 일단 기본값 True로 두기\n",
    "            neuron.IFNode(surrogate_function=surrogate.ATan(),v_reset= None if reset_value_residual else 0.0, v_threshold=threshold_value),\n",
    "            )\n",
    "\n",
    "        # SNN 리니어 : 인코더 출력 -> 히든\n",
    "        self.hidden = nn.Sequential(\n",
    "            # layer.Flatten(),\n",
    "            layer.Linear(hidden_size, hidden_size_2, bias=bias_option), # bias는 일단 기본값 True로 두기\n",
    "            neuron.IFNode(surrogate_function=surrogate.ATan(),v_reset= None if reset_value_residual else 0.0, v_threshold=threshold_value),\n",
    "            )\n",
    "        \n",
    "\n",
    "        # SNN 리니어 : 히든 -> 출력\n",
    "        self.layer = nn.Sequential(\n",
    "            # layer.Flatten(),\n",
    "            layer.Linear(hidden_size_2, num_classes, bias=bias_option), # bias는 일단 기본값 True로 두기\n",
    "            neuron.IFNode(surrogate_function=surrogate.ATan(),v_reset= None if reset_value_residual else 0.0, v_threshold=threshold_value),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        results = 0. # for문이 모델 안에 있으므로 밖에다가는 이녀석을 내보내야 함\n",
    "        # print(x.shape) # (배치크기, 187) 모양임\n",
    "        \n",
    "        timestep_size = x.shape[1] # 187 timestep을 만들어야 함\n",
    "        # 근데 이제 이렇게 바꾼 데이터는 (배치, 출력크기) 만큼의 값을 갖고 있으니 여기서 나온 값들을 하나씩 잘라서 다음 레이어로 넘겨야 한다.\n",
    "        for i in range(timestep_size) : \n",
    "            x_slice = x[:,i].squeeze().unsqueeze(1) # 슬라이스 진행 후 256, 1 크기가 되도록 shape 수정\n",
    "            x_slice = self.encoder(x_slice)\n",
    "            x_slice = self.hidden(x_slice)\n",
    "            x_slice = self.layer(x_slice)\n",
    "            results += x_slice  # 결과를 리스트에 저장(출력발화값은 전부 더하는 식으로)\n",
    "        # results = torch.stack(results, dim=0) # 텐서로 바꾸기\n",
    "        return results / timestep_size\n",
    "\n",
    "# 데이터 가져오는 알맹이 클래스\n",
    "class MITLoader_MLP_binary(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transforms: Callable = lambda x: x) -> None:\n",
    "        super().__init__()\n",
    "        self.annotations = pd.read_csv(csv_file).values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotations.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        signal = self.annotations[item, :-1]\n",
    "        signal = torch.from_numpy(signal).float()\n",
    "        if self.transforms : \n",
    "            signal = self.transforms(signal)\n",
    "        \n",
    "        label = int(self.annotations[item, -1])\n",
    "        if label > 0:\n",
    "            label = 1  # 1 이상인 모든 값은 1로 변환(난 이진값 처리하니깐)\n",
    "\n",
    "        return signal, torch.tensor(label).long()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01069519 0.01069519 0.01069519 ... 0.09625669 0.09625669 0.09625669]\n",
      " [0.03743315 0.03743315 0.03743315 ... 0.26737967 0.26737967 0.26737967]\n",
      " [0.01604278 0.01604278 0.01604278 ... 0.13903743 0.13903743 0.13903743]\n",
      " ...\n",
      " [0.03208556 0.03208556 0.03208556 ... 0.22459893 0.22459893 0.22459893]\n",
      " [0.03208556 0.03208556 0.03208556 ... 0.23529412 0.23529412 0.23529412]\n",
      " [0.02139037 0.02139037 0.02139037 ... 0.1764706  0.1764706  0.1764706 ]] [0 0 0 ... 0 0 0] 0.15018853820243996 625802429.0\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드 함수 정의\n",
    "def load_model(checkpoint_path_, model):\n",
    "    checkpoint = torch.load(checkpoint_path_)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    return model\n",
    "\n",
    "# Spike density 계산 함수 정의\n",
    "def compute_spike_density(encoder, data_loader):\n",
    "    spike_rates = []\n",
    "    labels = []\n",
    "    total_spike_count = 0\n",
    "    total_neurons = encoder[0].out_features  # hidden_size\n",
    "    total_samples = 0\n",
    "    timestep = 187  # MIT-BIH 데이터셋의 타임스텝 크기\n",
    "\n",
    "    encoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            functional.reset_net(encoder)  # SNN 상태 초기화\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            batch_size, seq_len = data.shape\n",
    "            total_samples += batch_size\n",
    "\n",
    "            spike_sum = torch.zeros(batch_size, total_neurons, device=device)\n",
    "\n",
    "            for i in range(seq_len):\n",
    "                x_slice = data[:, i].unsqueeze(1)\n",
    "                spikes = encoder(x_slice)\n",
    "                spike_sum += spikes\n",
    "\n",
    "            # 각 배치의 스파이크 총합 저장\n",
    "            batch_spike_count = spike_sum.sum().item()\n",
    "            total_spike_count += batch_spike_count\n",
    "\n",
    "            # 개별 샘플의 spike rate 저장 (T-SNE용)\n",
    "            spike_rate = spike_sum / seq_len\n",
    "            spike_rates.append(spike_rate.cpu().numpy())\n",
    "            labels.append(target.cpu().numpy())\n",
    "\n",
    "    spike_rates = np.concatenate(spike_rates, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    # 평균 스파이크 밀도 계산\n",
    "    avg_spike_density = total_spike_count / (total_samples * total_neurons * timestep)\n",
    "\n",
    "    return spike_rates, labels, avg_spike_density, total_spike_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 모델, 로더 지정\n",
    "dataset = MITLoader_MLP_binary(csv_file=test_path)\n",
    "data_loader = DataLoader(dataset, batch_size=256, shuffle=True, drop_last = True)\n",
    "\n",
    "# SNN 네트워크 초기화\n",
    "model = SNN_MLP(num_classes = num_classes, hidden_size=hidden_size, hidden_size_2=hidden_size_2, threshold_value=threshold_value, \n",
    "                bias_option=need_bias, reset_value_residual=reset_value_residual).to(device=device)\n",
    "\n",
    "# 모델 로드\n",
    "model = load_model(checkpoint_dir, model)\n",
    "\n",
    "# 스파이크 밀도 계산\n",
    "spike_rates, labels, avg_spike_density, total_spike_count = compute_spike_density(model.encoder, data_loader)\n",
    "\n",
    "print(spike_rates, labels, avg_spike_density, total_spike_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01069519 0.01069519 0.01069519 ... 0.09625669 0.09625669 0.09625669]\n",
      " [0.03743315 0.03743315 0.03743315 ... 0.26737967 0.26737967 0.26737967]\n",
      " [0.01604278 0.01604278 0.01604278 ... 0.13903743 0.13903743 0.13903743]\n",
      " ...\n",
      " [0.03208556 0.03208556 0.03208556 ... 0.22459893 0.22459893 0.22459893]\n",
      " [0.03208556 0.03208556 0.03208556 ... 0.23529412 0.23529412 0.23529412]\n",
      " [0.02139037 0.02139037 0.02139037 ... 0.1764706  0.1764706  0.1764706 ]] 0.15018853820243996 625802429.0\n",
      "(21760, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(spike_rates, avg_spike_density, total_spike_count)\n",
    "print(spike_rates.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_encoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
