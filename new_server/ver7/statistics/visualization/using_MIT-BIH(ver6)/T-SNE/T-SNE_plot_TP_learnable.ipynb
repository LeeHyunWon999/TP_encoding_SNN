{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-SNE 플롯 찍기용 (TP_learnable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 변수\n",
    "checkpoint_dir = \"/home/hschoi/data/leehyunwon/ECG-SNN/SNN_MLP_ver6_filter_CNN_IF_str16_2025-01-03-11-53-42_fold1_lastEpoch.pt\"\n",
    "config_json_dir = \"/home/hschoi/data/leehyunwon/ECG-SNN/SNN_MLP_ver6_filter_CNN_IF_str16_2025-01-03-11-53-42_fold1_config.json\"\n",
    "\n",
    "savefile_name = \"T-SNE_filterCNN.svg\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 17:12:33.049116: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-26 17:12:33.100019: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-26 17:12:33.869867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np # .npy 읽기용\n",
    "import pandas as pd # csv 읽기용\n",
    "import torch.nn.functional as F  # 일부 활성화 함수 등 파라미터 없는 함수에 사용\n",
    "import torchvision.datasets as datasets  # 일반적인 데이터셋; 이거 아마 MIT-BIH로 바꿔야 할 듯?\n",
    "import torchvision.transforms as transforms  # 데이터 증강을 위한 일종의 변형작업이라 함\n",
    "from torch import optim  # SGD, Adam 등의 옵티마이저(그래디언트는 이쪽으로 가면 됩니다)\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR # 코사인스케줄러(옵티마이저 보조용)\n",
    "from torch import nn  # 모든 DNN 모델들\n",
    "from torch.utils.data import (DataLoader, Dataset)  # 미니배치 등의 데이터셋 관리를 도와주는 녀석\n",
    "from tqdm import tqdm  # 진행도 표시용\n",
    "import torchmetrics # 평가지표 로깅용\n",
    "from typing import Callable # 람다식\n",
    "from torch.utils.tensorboard import SummaryWriter # tensorboard 기록용\n",
    "import time # 텐서보드 폴더명에 쓸 시각정보 기록용\n",
    "import random # 랜덤시드 고정용\n",
    "\n",
    "# 여긴 인코더 넣을때 혹시 몰라서 집어넣었음\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 얘는 SNN 학습이니까 당연히 있어야겠지? 특히 SNN 모델을 따로 만드려는 경우엔 뉴런 말고도 넣을 것이 많다.\n",
    "# import spikingjelly.activation_based as jelly\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, surrogate, layer\n",
    "\n",
    "from sklearn.model_selection import KFold # cross-validation용\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json파일 읽기 성공!\n",
      "Device :cuda\n"
     ]
    }
   ],
   "source": [
    "# 환경설정\n",
    "with open(config_json_dir, 'r') as f:\n",
    "    print(\"config.json파일 읽기 성공!\")\n",
    "    json_data = json.load(f)\n",
    "\n",
    "cuda_gpu = json_data['cuda_gpu']\n",
    "model_name = json_data['model_name']\n",
    "num_classes = json_data['num_classes']\n",
    "num_encoders = json_data['num_encoders']\n",
    "early_stop = json_data['early_stop']\n",
    "early_stop_enable = json_data['early_stop_enable']\n",
    "learning_rate = json_data['init_lr']\n",
    "batch_size = json_data['batch_size']\n",
    "num_epochs = json_data['num_epochs']\n",
    "train_path = json_data['train_path']\n",
    "test_path = json_data['test_path']\n",
    "class_weight = json_data['class_weight']\n",
    "encoder_min = json_data['encoder_min']\n",
    "encoder_max = json_data['encoder_max']\n",
    "hidden_size = json_data['hidden_size']\n",
    "hidden_size_2 = json_data['hidden_size_2']\n",
    "scheduler_tmax = json_data['scheduler_tmax']\n",
    "scheduler_eta_min = json_data['scheduler_eta_min']\n",
    "encoder_requires_grad = json_data['encoder_requires_grad']\n",
    "encoder_type = json_data['encoder_type']\n",
    "encoder_tp_iter_repeat = json_data['encoder_tp_iter_repeat']\n",
    "encoder_filter_kernel_size = json_data['encoder_filter_kernel_size']\n",
    "encoder_filter_stride = json_data['encoder_filter_stride']\n",
    "encoder_filter_padding = json_data['encoder_filter_padding']\n",
    "encoder_filter_channel_size = json_data['encoder_filter_channel_size'] # CNN 스타일로 가려면 채널갯수로 깊게 분석해야 할 것이다.\n",
    "random_seed = json_data['random_seed']\n",
    "checkpoint_save = json_data['checkpoint_save']\n",
    "checkpoint_path = json_data['checkpoint_path']\n",
    "threshold_value = json_data['threshold_value']\n",
    "reset_value_residual = json_data['reset_value_residual']\n",
    "need_bias = json_data['need_bias']\n",
    "k_folds = json_data['k_folds']\n",
    "\n",
    "# Cuda 써야겠지?\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # GPU 번호별로 0번부터 나열\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= str(cuda_gpu)  # 상황에 맞춰 변경할 것\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # 연산에 GPU 쓰도록 지정\n",
    "print(\"Device :\" + device) # 확인용\n",
    "# input() # 일시정지용\n",
    "\n",
    "# 랜덤시드 고정\n",
    "seed = random_seed\n",
    "deterministic = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "      \n",
    "\n",
    "# 여기선 CNN 인코딩 방식을 취했다.\n",
    "class SNN_MLP(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size, hidden_size_2, out_channels, kernel_size, stride, padding, threshold_value, bias_option, reset_value_residual):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN 인코더 필터 : 이건 그냥 갈긴다.\n",
    "        self.cnn_encoders = nn.Conv1d(in_channels=1, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                                      stride=stride, padding=padding, bias=bias_option) # 여기도 bias가 있다 함\n",
    "        \n",
    "        # CNN 인코더 IF뉴런 : 이거 추가해서 인코더 완성하기\n",
    "        self.cnn_IF_layer = neuron.IFNode(surrogate_function=surrogate.ATan(),v_reset= None if reset_value_residual else 0.0, v_threshold=threshold_value)\n",
    "        \n",
    "        # SNN 리니어 : 인코더 입력 -> 히든\n",
    "        self.hidden = nn.Sequential(\n",
    "            # layer.Flatten(),\n",
    "            layer.Linear(out_channels, hidden_size, bias=bias_option), # bias는 일단 기본값 True로 두기\n",
    "            neuron.IFNode(surrogate_function=surrogate.ATan(),v_reset= None if reset_value_residual else 0.0, v_threshold=threshold_value),\n",
    "            )\n",
    "\n",
    "        # SNN 리니어 : 히든 -> 출력\n",
    "        self.layer = nn.Sequential(\n",
    "            # layer.Flatten(),\n",
    "            layer.Linear(hidden_size, num_classes, bias=bias_option), # bias는 일단 기본값 True로 두기\n",
    "            neuron.IFNode(surrogate_function=surrogate.ATan(),v_reset= None if reset_value_residual else 0.0, v_threshold=threshold_value),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        results = 0. # for문이 모델 안에 있으므로 밖에다가는 이녀석을 내보내야 함\n",
    "        \n",
    "        # CNN 필터는 채널 차원이 추가되므로 1번 쪽에 채널 차원 추가\n",
    "        x = x.unsqueeze(1)\n",
    "        # CNN 필터 통과시키기\n",
    "        x = self.cnn_encoders(x)\n",
    "        # print(x.shape)\n",
    "        timestep_size = x.shape[2]\n",
    "        # 근데 이제 이렇게 바꾼 데이터는 (배치, 채널, 출력크기) 만큼의 값을 갖고 있으니 여기서 나온 값들을 하나씩 잘라서 다음 레이어로 넘겨야 한다.\n",
    "        for i in range(timestep_size) : \n",
    "            x_slice = x[:,:,i].squeeze() # 이러면 출력크기 차원이 사라지고 (배치, 채널)만 남겠지?\n",
    "            x_slice = self.cnn_IF_layer(x_slice) # CNN 필터 이후 IF 레이어 거치기\n",
    "            x_slice = self.hidden(x_slice)\n",
    "            # x_slice = self.hidden_2(x_slice)\n",
    "            x_slice = self.layer(x_slice)\n",
    "            results += x_slice  # 결과를 리스트에 저장(출력발화값은 전부 더하는 식으로)\n",
    "        # results = torch.stack(results, dim=0) # 텐서로 바꾸기\n",
    "        return results / timestep_size\n",
    "\n",
    "# 데이터 가져오는 알맹이 클래스\n",
    "class MITLoader_MLP_binary(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transforms: Callable = lambda x: x) -> None:\n",
    "        super().__init__()\n",
    "        self.annotations = pd.read_csv(csv_file).values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotations.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        signal = self.annotations[item, :-1]\n",
    "        signal = torch.from_numpy(signal).float()\n",
    "        if self.transforms : \n",
    "            signal = self.transforms(signal)\n",
    "        \n",
    "        label = int(self.annotations[item, -1])\n",
    "        if label > 0:\n",
    "            label = 1  # 1 이상인 모든 값은 1로 변환(난 이진값 처리하니깐)\n",
    "\n",
    "        return signal, torch.tensor(label).long()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 완료, 시각화중...\n",
      "Saved: T-SNE_filterCNN.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 모델 로드 함수 정의\n",
    "def load_model(checkpoint_path_, model):\n",
    "    checkpoint = torch.load(checkpoint_path_)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    return model\n",
    "\n",
    "# Spike rate 계산 함수 정의\n",
    "def compute_spike_rate(encoder, cnn_IF_layer, data_loader):\n",
    "    spike_rates = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            functional.reset_net(encoder) # SNN 모델 매 순전파마다 초기화\n",
    "            functional.reset_net(cnn_IF_layer)\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # CNN 인코더 통과\n",
    "            x = encoder(data.unsqueeze(1))\n",
    "            timestep_size = x.shape[2]\n",
    "\n",
    "            # 시간축 반복하여 Spike 계산\n",
    "            spike_sum = torch.zeros(x.shape[0], x.shape[1], device=device)  # 배치와 채널 크기로 초기화\n",
    "            for i in range(timestep_size):\n",
    "                x_slice = x[:, :, i].squeeze()\n",
    "                spikes = cnn_IF_layer(x_slice)\n",
    "                spike_sum += spikes\n",
    "\n",
    "            # Spike rate 계산 (스파이크 총합 / 필터 크기)\n",
    "            spike_rate = spike_sum / timestep_size\n",
    "            spike_rates.append(spike_rate.cpu().numpy())\n",
    "            labels.append(target.cpu().numpy())\n",
    "\n",
    "    spike_rates = np.concatenate(spike_rates, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return spike_rates, labels\n",
    "\n",
    "def plot_tsne_with_silhouette_2(spike_rates, labels, savefile_name):\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(spike_rates)\n",
    "    silhouette_val = silhouette_score(spike_rates, labels)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    scatter = ax.scatter(\n",
    "        tsne_results[:, 0], tsne_results[:, 1], \n",
    "        c=labels, cmap='tab10', alpha=0.6\n",
    "    )\n",
    "\n",
    "    # Silhouette 값 텍스트 삽입 (우측 하단)\n",
    "    ax.text(\n",
    "        0.98, 0.02,\n",
    "        f'Silhouette Value: {silhouette_val:.4f}',\n",
    "        fontsize=16,\n",
    "        transform=ax.transAxes,\n",
    "        ha='right',\n",
    "        va='bottom',\n",
    "        bbox=dict(facecolor='lightgray', alpha=0.5, boxstyle='round,pad=0.3')\n",
    "    )\n",
    "\n",
    "    # 제목, 축 라벨 제거 (눈금과 틱은 유지)\n",
    "    ax.set_title(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "    # 눈금 숫자, 눈금선, 박스는 모두 기본 유지됨\n",
    "    plt.savefig(savefile_name, format=\"svg\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Saved: {savefile_name}\")\n",
    "\n",
    "\n",
    "# 모델, 로더 지정\n",
    "dataset = MITLoader_MLP_binary(csv_file=test_path)\n",
    "data_loader = DataLoader(dataset, batch_size=256, shuffle=True, drop_last = True)\n",
    "\n",
    "# SNN 네트워크 초기화\n",
    "model = SNN_MLP(num_classes = num_classes, hidden_size=hidden_size, hidden_size_2=hidden_size_2, \n",
    "            out_channels=encoder_filter_channel_size, kernel_size=encoder_filter_kernel_size, \n",
    "            stride=encoder_filter_stride, padding=encoder_filter_padding, threshold_value=threshold_value, \n",
    "            bias_option=need_bias, reset_value_residual=reset_value_residual).to(device=device)\n",
    "\n",
    "# 모델 로드\n",
    "model = load_model(checkpoint_dir, model)\n",
    "\n",
    "# 스파이크 레이트 계산\n",
    "spike_rates, labels = compute_spike_rate(model.cnn_encoders, model.cnn_IF_layer, data_loader)\n",
    "\n",
    "# T-SNE 시각화\n",
    "print(\"인코딩 완료, 시각화중...\")\n",
    "plot_tsne_with_silhouette_2(spike_rates, labels, savefile_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1229105\n"
     ]
    }
   ],
   "source": [
    "# 실루엣값만 따로 보기\n",
    "silhouette_val = silhouette_score(spike_rates, labels)\n",
    "print(silhouette_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_encoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
