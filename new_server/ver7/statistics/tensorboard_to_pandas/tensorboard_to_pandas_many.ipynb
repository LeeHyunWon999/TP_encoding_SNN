{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드로부터 값 뽑아내는 작업, 근데 이제 여러 텐서보드 로그를 취합하는.\n",
    "\n",
    "valid_AUROC 기준 최고성능인 epoch의 통계값들을 뽑아내면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 변수 넣기\n",
    "tensorboard_dirs_txt = '/home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/statistics/tensorboard_to_pandas/CinC_original_1.txt'\n",
    "output_file_name = 'CinC_original_1.csv'\n",
    "\n",
    "tags = ['train_Loss','train_Accuracy','train_F1_micro','train_F1_weighted','train_AUROC_macro','train_AUROC_weighted','train_auprc', 'valid_Loss','valid_Accuracy','valid_F1_micro','valid_F1_weighted', 'valid_AUROC_macro','valid_AUROC_weighted','valid_auprc']\n",
    "usable_tags = ['valid_Accuracy','valid_F1_micro', 'valid_AUROC_macro', 'valid_auprc'] # 일반적인 경우 아래 대신 이거 선택\n",
    "# usable_tags = ['valid_AUROC_macro'] # stride 보려면 이것만 있어도 될 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tensorboard_dirs_txt, 'r', encoding='utf-8') as file:\n",
    "    tensorboard_dirs = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/burst_CinC_original_2025-04-27-18-56-06_fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 10:42:20.474915: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-28 10:42:20.530169: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-28 10:42:21.311125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/burst_CinC_original_2025-04-27-18-56-06_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/burst_CinC_original_2025-04-27-18-56-06_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/burst_CinC_original_2025-04-27-18-56-06_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/burst_CinC_original_2025-04-27-18-56-06_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/filter_CNN_2D_CinC_original_2025-04-27-19-06-05_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/filter_CNN_2D_CinC_original_2025-04-27-19-06-05_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/filter_CNN_2D_CinC_original_2025-04-27-19-06-05_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/filter_CNN_2D_CinC_original_2025-04-27-19-06-05_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/filter_CNN_2D_CinC_original_2025-04-27-19-06-05_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/poisson_CinC_original_2025-04-27-18-57-34_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/poisson_CinC_original_2025-04-27-18-57-34_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/poisson_CinC_original_2025-04-27-18-57-34_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/poisson_CinC_original_2025-04-27-18-57-34_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/poisson_CinC_original_2025-04-27-18-57-34_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/TP_2D_CinC_original_2025-04-27-19-14-52_fold1\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/TP_2D_CinC_original_2025-04-27-19-14-52_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/TP_2D_CinC_original_2025-04-27-19-14-52_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/TP_2D_CinC_original_2025-04-27-19-14-52_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/CinC_original/1_hidden_256/TP_2D_CinC_original_2025-04-27-19-14-52_fold5\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "\n",
      "Final DataFrame with Highest AUROC Rows:\n",
      "     epoch  valid_Accuracy  valid_F1_micro  valid_AUROC_macro  valid_auprc  \\\n",
      "399  399.0        0.813272        0.187919           0.545482     0.261542   \n",
      "364  364.0        0.790123        0.218391           0.551298     0.309129   \n",
      "991  991.0        0.759259        0.235294           0.545517     0.273613   \n",
      "341  341.0        0.791667        0.219653           0.551040     0.312883   \n",
      "340  340.0        0.788580        0.243094           0.558421     0.304652   \n",
      "488  488.0        0.825617        0.542510           0.718072     0.484806   \n",
      "400  400.0        0.802469        0.525926           0.699506     0.496149   \n",
      "899  899.0        0.797840        0.540351           0.711550     0.488919   \n",
      "619  619.0        0.785494        0.547231           0.728411     0.498902   \n",
      "911  911.0        0.788580        0.475096           0.666418     0.489216   \n",
      "338  338.0        0.776235        0.435798           0.653357     0.395010   \n",
      "550  550.0        0.785494        0.446215           0.648265     0.415451   \n",
      "960  960.0        0.760802        0.463668           0.661355     0.409662   \n",
      "850  850.0        0.782407        0.459770           0.659544     0.430877   \n",
      "980  980.0        0.760802        0.382470           0.611041     0.388906   \n",
      "0      1.0        0.810185        0.000000           0.500000     0.221631   \n",
      "879  879.0        0.791667        0.014599           0.503676     0.223464   \n",
      "142  142.0        0.631173        0.255452           0.509713     0.222671   \n",
      "243  243.0        0.209877        0.341902           0.502913     0.202408   \n",
      "0      1.0        0.790123        0.000000           0.500000     0.246152   \n",
      "\n",
      "                                            source_dir  total elapsed minute  \\\n",
      "399      burst_CinC_original_2025-04-27-18-56-06_fold1             53.269426   \n",
      "364      burst_CinC_original_2025-04-27-18-56-06_fold2             46.885006   \n",
      "991      burst_CinC_original_2025-04-27-18-56-06_fold3            100.819789   \n",
      "341      burst_CinC_original_2025-04-27-18-56-06_fold4             34.486563   \n",
      "340      burst_CinC_original_2025-04-27-18-56-06_fold5             34.632327   \n",
      "488  filter_CNN_2D_CinC_original_2025-04-27-19-06-0...             18.625288   \n",
      "400  filter_CNN_2D_CinC_original_2025-04-27-19-06-0...             16.697186   \n",
      "899  filter_CNN_2D_CinC_original_2025-04-27-19-06-0...             37.189553   \n",
      "619  filter_CNN_2D_CinC_original_2025-04-27-19-06-0...             25.613613   \n",
      "911  filter_CNN_2D_CinC_original_2025-04-27-19-06-0...             38.050772   \n",
      "338    poisson_CinC_original_2025-04-27-18-57-34_fold1             16.058750   \n",
      "550    poisson_CinC_original_2025-04-27-18-57-34_fold2             29.044137   \n",
      "960    poisson_CinC_original_2025-04-27-18-57-34_fold3             50.807853   \n",
      "850    poisson_CinC_original_2025-04-27-18-57-34_fold4             45.317449   \n",
      "980    poisson_CinC_original_2025-04-27-18-57-34_fold5             46.992203   \n",
      "0        TP_2D_CinC_original_2025-04-27-19-14-52_fold1              0.169148   \n",
      "879      TP_2D_CinC_original_2025-04-27-19-14-52_fold2            124.214268   \n",
      "142      TP_2D_CinC_original_2025-04-27-19-14-52_fold3             18.097018   \n",
      "243      TP_2D_CinC_original_2025-04-27-19-14-52_fold4             31.148280   \n",
      "0        TP_2D_CinC_original_2025-04-27-19-14-52_fold5              0.122380   \n",
      "\n",
      "     minute per epoch  \n",
      "399          0.133507  \n",
      "364          0.128805  \n",
      "991          0.101735  \n",
      "341          0.101134  \n",
      "340          0.101860  \n",
      "488          0.038167  \n",
      "400          0.041743  \n",
      "899          0.041368  \n",
      "619          0.041379  \n",
      "911          0.041768  \n",
      "338          0.047511  \n",
      "550          0.052808  \n",
      "960          0.052925  \n",
      "850          0.053315  \n",
      "980          0.047951  \n",
      "0            0.169148  \n",
      "879          0.141313  \n",
      "142          0.127444  \n",
      "243          0.128182  \n",
      "0            0.122380  \n"
     ]
    }
   ],
   "source": [
    "# 병합된 데이터 저장용 리스트\n",
    "highest_rows = []\n",
    "\n",
    "for dir_path in tensorboard_dirs: # 각 로그마다\n",
    "    print(f\"Processing TensorBoard log: {dir_path}\")\n",
    "    ea = event_accumulator.EventAccumulator(dir_path)\n",
    "    ea.Reload() # 텐서보드 로그 뽑아서 변수에 넣기기\n",
    "    \n",
    "    data = {} # 수집된 데이터를 저장할 딕셔너리\n",
    "    epoch_time_map = {}  # 에포크와 wall_time 매핑\n",
    "\n",
    "    # 태그(메트릭) 별로 에포크와 값 빼내서 저장\n",
    "    for tag in tags:\n",
    "        if tag in ea.Tags()[\"scalars\"]:  # 태그가 존재하는지 확인\n",
    "            events = ea.Scalars(tag)\n",
    "            data[tag] = {\n",
    "                \"epoch\": [event.step for event in events],  # step을 epoch으로 사용\n",
    "                \"value\": [event.value for event in events],\n",
    "            }\n",
    "            # epoch -> wall_time 매핑 (처음 태그에서만 추출)\n",
    "            if not epoch_time_map:\n",
    "                epoch_time_map = {event.step: event.wall_time for event in events}\n",
    "        else:\n",
    "            print(f\"Tag '{tag}' not found in the TensorBoard logs.\")\n",
    "\n",
    "    # 태그별 데이터프레임 생성\n",
    "    dataframes = {tag: pd.DataFrame(values) for tag, values in data.items()}\n",
    "\n",
    "    # 단일 데이터프레임으로 병합 (Epoch 기준)\n",
    "    merged_df = pd.DataFrame({\"epoch\": dataframes[tags[0]][\"epoch\"]})  # 첫 태그의 epoch 사용\n",
    "    for tag in tags:\n",
    "        if tag in dataframes:\n",
    "            merged_df[tag] = dataframes[tag][\"value\"]\n",
    "\n",
    "    # 필요한 태그로 필터링\n",
    "    filtered_df = merged_df[['epoch'] + [tag for tag in usable_tags if tag in merged_df.columns]] # 에포크도 보고 싶으니 추가\n",
    "\n",
    "    # 가장 높은 AUROC 값을 갖는 행 추출\n",
    "    if \"valid_AUROC_macro\" in filtered_df.columns:\n",
    "        highest_row = filtered_df.loc[filtered_df['valid_AUROC_macro'].idxmax()].copy()  # 명시적 복사\n",
    "        highest_row[\"source_dir\"] = dir_path.split('/')[-1]  # 로그 출처 추가\n",
    "\n",
    "        # 학습 시간 계산\n",
    "        highest_epoch = int(highest_row['epoch'])\n",
    "        # print(highest_epoch) # 확인 필요\n",
    "\n",
    "        # 최고 에포크가 0으로 나오는 경우는 편의상 1로 계산..\n",
    "        if highest_epoch == 0 : \n",
    "            print(\"최고 에포크 0, 편의상 1로 변경\")\n",
    "            highest_epoch = 1\n",
    "        if highest_row['epoch'] == 0 : \n",
    "            print(\"최고 에포크 0, 편의상 1로 변경\")\n",
    "            highest_row['epoch'] = 1\n",
    "\n",
    "        if highest_epoch in epoch_time_map:\n",
    "            start_time = min(epoch_time_map.values())  # 첫 epoch 시작 시간\n",
    "            end_time = epoch_time_map[highest_epoch]  # 최고 성능 epoch의 시간\n",
    "            elapsed_time = (end_time - start_time) / 60 # 경과 시간 계산 (분)\n",
    "            highest_row[\"total elapsed minute\"] = elapsed_time\n",
    "            highest_row[\"minute per epoch\"] = elapsed_time / highest_row['epoch']\n",
    "        else:\n",
    "            highest_row[\"total elapsed minute\"] = None\n",
    "            highest_row[\"minute per epoch\"] = None  # 해당 에포크 시간 데이터 없음\n",
    "\n",
    "        highest_rows.append(highest_row)\n",
    "\n",
    "# 최종 병합\n",
    "final_df = pd.DataFrame(highest_rows)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\nFinal DataFrame with Highest AUROC Rows:\")\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장하기\n",
    "final_df.to_csv(output_file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_encoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
