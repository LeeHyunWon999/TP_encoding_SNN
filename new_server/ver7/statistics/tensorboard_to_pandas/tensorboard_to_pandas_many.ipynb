{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드로부터 값 뽑아내는 작업, 근데 이제 여러 텐서보드 로그를 취합하는.\n",
    "\n",
    "valid_AUROC 기준 최고성능인 epoch의 통계값들을 뽑아내면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 변수 넣기\n",
    "tensorboard_dirs_txt = '/home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/statistics/tensorboard_to_pandas/fordA_1.txt'\n",
    "output_file_name = 'fordA_1.csv'\n",
    "\n",
    "tags = ['train_Loss','train_Accuracy','train_F1_micro','train_F1_weighted','train_AUROC_macro','train_AUROC_weighted','train_auprc', 'valid_Loss','valid_Accuracy','valid_F1_micro','valid_F1_weighted', 'valid_AUROC_macro','valid_AUROC_weighted','valid_auprc']\n",
    "usable_tags = ['valid_Accuracy','valid_F1_weighted', 'valid_AUROC_macro', 'valid_auprc'] # 일반적인 경우 아래 대신 이거 선택\n",
    "# usable_tags = ['valid_AUROC_macro'] # stride 보려면 이것만 있어도 될 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tensorboard_dirs_txt, 'r', encoding='utf-8') as file:\n",
    "    tensorboard_dirs = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/burst_fordA_2025-05-03-19-21-37_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/burst_fordA_2025-05-03-19-21-37_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/burst_fordA_2025-05-03-19-21-37_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/burst_fordA_2025-05-03-19-21-37_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/burst_fordA_2025-05-03-19-21-37_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/filter_CNN_2D_fordA_2025-05-05-00-21-38_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/filter_CNN_2D_fordA_2025-05-05-00-21-38_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/filter_CNN_2D_fordA_2025-05-05-00-21-38_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/filter_CNN_2D_fordA_2025-05-05-00-21-38_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/filter_CNN_2D_fordA_2025-05-05-00-21-38_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/poisson_fordA_2025-05-05-03-53-34_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/poisson_fordA_2025-05-05-03-53-34_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/poisson_fordA_2025-05-05-03-53-34_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/poisson_fordA_2025-05-05-03-53-34_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/poisson_fordA_2025-05-05-03-53-34_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_2D_fordA_2025-05-05-08-59-30_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_2D_fordA_2025-05-05-08-59-30_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_2D_fordA_2025-05-05-08-59-30_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_2D_fordA_2025-05-05-08-59-30_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_2D_fordA_2025-05-05-08-59-30_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_learnable_2D_fordA_2025-05-05-23-28-47_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_learnable_2D_fordA_2025-05-05-23-28-47_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_learnable_2D_fordA_2025-05-05-23-28-47_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_learnable_2D_fordA_2025-05-05-23-28-47_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/fordA/1_hidden_128/TP_learnable_2D_fordA_2025-05-05-23-28-47_fold5\n",
      "\n",
      "Final DataFrame with Highest AUROC Rows:\n",
      "     epoch  valid_Accuracy  valid_F1_weighted  valid_AUROC_macro  valid_auprc  \\\n",
      "884  884.0        0.642164           0.641806           0.687617     0.677543   \n",
      "560  560.0        0.656944           0.657002           0.706059     0.693206   \n",
      "488  488.0        0.647222           0.647255           0.687590     0.677474   \n",
      "628  628.0        0.641667           0.641445           0.684949     0.667586   \n",
      "704  704.0        0.652778           0.652778           0.705282     0.690342   \n",
      "991  991.0        0.915395           0.915372           0.969635     0.967639   \n",
      "757  757.0        0.894444           0.894398           0.956739     0.954562   \n",
      "783  783.0        0.898611           0.898571           0.963673     0.961521   \n",
      "637  637.0        0.883333           0.883333           0.967132     0.966926   \n",
      "703  703.0        0.908333           0.908322           0.969967     0.969017   \n",
      "964  964.0        0.780860           0.780721           0.872466     0.870294   \n",
      "966  966.0        0.763889           0.763940           0.861575     0.859368   \n",
      "996  996.0        0.751389           0.751405           0.817373     0.810039   \n",
      "968  968.0        0.754167           0.754194           0.836441     0.831994   \n",
      "996  996.0        0.752778           0.752709           0.828283     0.826546   \n",
      "266  266.0        0.638003           0.631658           0.676944     0.666250   \n",
      "866  866.0        0.568056           0.563509           0.652408     0.647155   \n",
      "972  972.0        0.625000           0.620218           0.683700     0.671297   \n",
      "130  130.0        0.565278           0.520146           0.671962     0.647372   \n",
      "971  971.0        0.573611           0.525624           0.670693     0.653013   \n",
      "999  999.0        0.649098           0.631264           0.719698     0.709899   \n",
      "985  985.0        0.615278           0.614927           0.661001     0.656875   \n",
      "979  979.0        0.525000           0.399177           0.688140     0.678342   \n",
      "989  989.0        0.666667           0.661354           0.717116     0.704571   \n",
      "942  942.0        0.523611           0.419430           0.683003     0.661076   \n",
      "\n",
      "                                          source_dir  total elapsed minute  \\\n",
      "884            burst_fordA_2025-05-03-19-21-37_fold1            304.156350   \n",
      "560            burst_fordA_2025-05-03-19-21-37_fold2            195.959137   \n",
      "488            burst_fordA_2025-05-03-19-21-37_fold3            170.113391   \n",
      "628            burst_fordA_2025-05-03-19-21-37_fold4            218.756229   \n",
      "704            burst_fordA_2025-05-03-19-21-37_fold5            245.625732   \n",
      "991    filter_CNN_2D_fordA_2025-05-05-00-21-38_fold1             42.451867   \n",
      "757    filter_CNN_2D_fordA_2025-05-05-00-21-38_fold2             32.266829   \n",
      "783    filter_CNN_2D_fordA_2025-05-05-00-21-38_fold3             33.056097   \n",
      "637    filter_CNN_2D_fordA_2025-05-05-00-21-38_fold4             26.872144   \n",
      "703    filter_CNN_2D_fordA_2025-05-05-00-21-38_fold5             29.430382   \n",
      "964          poisson_fordA_2025-05-05-03-53-34_fold1             59.419940   \n",
      "966          poisson_fordA_2025-05-05-03-53-34_fold2             58.944829   \n",
      "996          poisson_fordA_2025-05-05-03-53-34_fold3             60.939921   \n",
      "968          poisson_fordA_2025-05-05-03-53-34_fold4             58.986127   \n",
      "996          poisson_fordA_2025-05-05-03-53-34_fold5             60.639381   \n",
      "266            TP_2D_fordA_2025-05-05-08-59-30_fold1             46.481024   \n",
      "866            TP_2D_fordA_2025-05-05-08-59-30_fold2            150.293433   \n",
      "972            TP_2D_fordA_2025-05-05-08-59-30_fold3            168.998037   \n",
      "130            TP_2D_fordA_2025-05-05-08-59-30_fold4             22.564381   \n",
      "971            TP_2D_fordA_2025-05-05-08-59-30_fold5            168.561516   \n",
      "999  TP_learnable_2D_fordA_2025-05-05-23-28-47_fold1            209.885388   \n",
      "985  TP_learnable_2D_fordA_2025-05-05-23-28-47_fold2            193.618545   \n",
      "979  TP_learnable_2D_fordA_2025-05-05-23-28-47_fold3            174.900222   \n",
      "989  TP_learnable_2D_fordA_2025-05-05-23-28-47_fold4            177.279254   \n",
      "942  TP_learnable_2D_fordA_2025-05-05-23-28-47_fold5            174.507269   \n",
      "\n",
      "     minute per epoch  \n",
      "884          0.344068  \n",
      "560          0.349927  \n",
      "488          0.348593  \n",
      "628          0.348338  \n",
      "704          0.348900  \n",
      "991          0.042837  \n",
      "757          0.042625  \n",
      "783          0.042217  \n",
      "637          0.042185  \n",
      "703          0.041864  \n",
      "964          0.061639  \n",
      "966          0.061019  \n",
      "996          0.061185  \n",
      "968          0.060936  \n",
      "996          0.060883  \n",
      "266          0.174741  \n",
      "866          0.173549  \n",
      "972          0.173866  \n",
      "130          0.173572  \n",
      "971          0.173596  \n",
      "999          0.210095  \n",
      "985          0.196567  \n",
      "979          0.178652  \n",
      "989          0.179251  \n",
      "942          0.185252  \n"
     ]
    }
   ],
   "source": [
    "# 병합된 데이터 저장용 리스트\n",
    "highest_rows = []\n",
    "\n",
    "for dir_path in tensorboard_dirs: # 각 로그마다\n",
    "    print(f\"Processing TensorBoard log: {dir_path}\")\n",
    "    ea = event_accumulator.EventAccumulator(dir_path)\n",
    "    ea.Reload() # 텐서보드 로그 뽑아서 변수에 넣기기\n",
    "    \n",
    "    data = {} # 수집된 데이터를 저장할 딕셔너리\n",
    "    epoch_time_map = {}  # 에포크와 wall_time 매핑\n",
    "\n",
    "    # 태그(메트릭) 별로 에포크와 값 빼내서 저장\n",
    "    for tag in tags:\n",
    "        if tag in ea.Tags()[\"scalars\"]:  # 태그가 존재하는지 확인\n",
    "            events = ea.Scalars(tag)\n",
    "            data[tag] = {\n",
    "                \"epoch\": [event.step for event in events],  # step을 epoch으로 사용\n",
    "                \"value\": [event.value for event in events],\n",
    "            }\n",
    "            # epoch -> wall_time 매핑 (처음 태그에서만 추출)\n",
    "            if not epoch_time_map:\n",
    "                epoch_time_map = {event.step: event.wall_time for event in events}\n",
    "        else:\n",
    "            print(f\"Tag '{tag}' not found in the TensorBoard logs.\")\n",
    "\n",
    "    # 태그별 데이터프레임 생성\n",
    "    dataframes = {tag: pd.DataFrame(values) for tag, values in data.items()}\n",
    "\n",
    "    # 단일 데이터프레임으로 병합 (Epoch 기준)\n",
    "    merged_df = pd.DataFrame({\"epoch\": dataframes[tags[0]][\"epoch\"]})  # 첫 태그의 epoch 사용\n",
    "    for tag in tags:\n",
    "        if tag in dataframes:\n",
    "            merged_df[tag] = dataframes[tag][\"value\"]\n",
    "\n",
    "    # 필요한 태그로 필터링\n",
    "    filtered_df = merged_df[['epoch'] + [tag for tag in usable_tags if tag in merged_df.columns]] # 에포크도 보고 싶으니 추가\n",
    "\n",
    "    # 가장 높은 AUROC 값을 갖는 행 추출\n",
    "    if \"valid_AUROC_macro\" in filtered_df.columns:\n",
    "        highest_row = filtered_df.loc[filtered_df['valid_AUROC_macro'].idxmax()].copy()  # 명시적 복사\n",
    "        highest_row[\"source_dir\"] = dir_path.split('/')[-1]  # 로그 출처 추가\n",
    "\n",
    "        # 학습 시간 계산\n",
    "        highest_epoch = int(highest_row['epoch'])\n",
    "        # print(highest_epoch) # 확인 필요\n",
    "\n",
    "        # 최고 에포크가 0으로 나오는 경우는 편의상 1로 계산..\n",
    "        if highest_epoch == 0 : \n",
    "            print(\"최고 에포크 0, 편의상 1로 변경\")\n",
    "            highest_epoch = 1\n",
    "        if highest_row['epoch'] == 0 : \n",
    "            print(\"최고 에포크 0, 편의상 1로 변경\")\n",
    "            highest_row['epoch'] = 1\n",
    "\n",
    "        if highest_epoch in epoch_time_map:\n",
    "            start_time = min(epoch_time_map.values())  # 첫 epoch 시작 시간\n",
    "            end_time = epoch_time_map[highest_epoch]  # 최고 성능 epoch의 시간\n",
    "            elapsed_time = (end_time - start_time) / 60 # 경과 시간 계산 (분)\n",
    "            highest_row[\"total elapsed minute\"] = elapsed_time\n",
    "            highest_row[\"minute per epoch\"] = elapsed_time / highest_row['epoch']\n",
    "        else:\n",
    "            highest_row[\"total elapsed minute\"] = None\n",
    "            highest_row[\"minute per epoch\"] = None  # 해당 에포크 시간 데이터 없음\n",
    "\n",
    "        highest_rows.append(highest_row)\n",
    "\n",
    "# 최종 병합\n",
    "final_df = pd.DataFrame(highest_rows)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\nFinal DataFrame with Highest AUROC Rows:\")\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장하기\n",
    "final_df.to_csv(output_file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_encoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
