{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드로부터 값 뽑아내는 작업, 근데 이제 여러 텐서보드 로그를 취합하는.\n",
    "\n",
    "valid_AUROC 기준 최고성능인 epoch의 통계값들을 뽑아내면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 변수 넣기\n",
    "tensorboard_dirs_txt = '/home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/statistics/tensorboard_to_pandas/faultD_1.txt'\n",
    "output_file_name = 'faultD_1.csv'\n",
    "\n",
    "tags = ['train_Loss','train_Accuracy','train_F1_micro','train_F1_weighted','train_AUROC_macro','train_AUROC_weighted','train_auprc', 'valid_Loss','valid_Accuracy','valid_F1_micro','valid_F1_weighted', 'valid_AUROC_macro','valid_AUROC_weighted','valid_auprc']\n",
    "usable_tags = ['valid_Accuracy','valid_F1_weighted', 'valid_AUROC_macro', 'valid_auprc'] # 일반적인 경우 아래 대신 이거 선택\n",
    "# usable_tags = ['valid_AUROC_macro'] # stride 보려면 이것만 있어도 될 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tensorboard_dirs_txt, 'r', encoding='utf-8') as file:\n",
    "    tensorboard_dirs = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/burst_faultD_2025-05-03-19-22-11_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/burst_faultD_2025-05-03-19-22-11_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/burst_faultD_2025-05-03-19-22-11_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/burst_faultD_2025-05-03-19-22-11_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/burst_faultD_2025-05-03-19-22-11_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/filter_CNN_2D_faultD_2025-05-06-04-23-15_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/filter_CNN_2D_faultD_2025-05-06-04-23-15_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/filter_CNN_2D_faultD_2025-05-06-04-23-15_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/filter_CNN_2D_faultD_2025-05-06-04-23-15_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/filter_CNN_2D_faultD_2025-05-06-04-23-15_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/poisson_faultD_2025-05-06-15-47-30_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/poisson_faultD_2025-05-06-15-47-30_fold2\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/poisson_faultD_2025-05-06-15-47-30_fold3\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/poisson_faultD_2025-05-06-15-47-30_fold4\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/poisson_faultD_2025-05-06-15-47-30_fold5\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/TP_2D_faultD_2025-05-06-23-59-05_fold1\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/TP_2D_faultD_2025-05-06-23-59-05_fold2\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/TP_2D_faultD_2025-05-06-23-59-05_fold3\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/TP_2D_faultD_2025-05-06-23-59-05_fold4\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "Processing TensorBoard log: /home/hschoi/leehyunwon/ECG-SNN/new_server/ver7/IF/tensorboard/faultD/1_hidden_128/TP_2D_faultD_2025-05-06-23-59-05_fold5\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "최고 에포크 0, 편의상 1로 변경\n",
      "\n",
      "Final DataFrame with Highest AUROC Rows:\n",
      "     epoch  valid_Accuracy  valid_F1_weighted  valid_AUROC_macro  valid_auprc  \\\n",
      "12    12.0        0.453046           0.331249           0.648097     0.441134   \n",
      "10    10.0        0.333486           0.346866           0.588945     0.390740   \n",
      "12    12.0        0.474794           0.443110           0.622595     0.421231   \n",
      "2      2.0        0.479835           0.332077           0.669057     0.479620   \n",
      "742  742.0        0.500000           0.491599           0.650218     0.443710   \n",
      "997  997.0        0.786532           0.779695           0.933008     0.914814   \n",
      "959  959.0        0.806230           0.800088           0.945559     0.933421   \n",
      "998  998.0        0.773602           0.767187           0.926292     0.892353   \n",
      "996  996.0        0.807058           0.803453           0.945036     0.930249   \n",
      "957  957.0        0.811641           0.808596           0.943852     0.929057   \n",
      "896  896.0        0.312872           0.259730           0.532308     0.354963   \n",
      "290  290.0        0.086578           0.013797           0.579588     0.387255   \n",
      "15    15.0        0.087076           0.013950           0.543119     0.367401   \n",
      "65    65.0        0.324015           0.261828           0.538189     0.366689   \n",
      "216  216.0        0.092576           0.015688           0.539104     0.360241   \n",
      "930  930.0        0.592762           0.534391           0.690794     0.580632   \n",
      "0      1.0        0.475492           0.306465           0.672856     0.431613   \n",
      "0      1.0        0.445005           0.274088           0.500000     0.333333   \n",
      "0      1.0        0.433089           0.261765           0.500000     0.333333   \n",
      "0      1.0        0.439963           0.268851           0.500000     0.333333   \n",
      "\n",
      "                                         source_dir  total elapsed minute  \\\n",
      "12           burst_faultD_2025-05-03-19-22-11_fold1             13.725204   \n",
      "10           burst_faultD_2025-05-03-19-22-11_fold2             11.485705   \n",
      "12           burst_faultD_2025-05-03-19-22-11_fold3              6.451036   \n",
      "2            burst_faultD_2025-05-03-19-22-11_fold4              0.875922   \n",
      "742          burst_faultD_2025-05-03-19-22-11_fold5            327.387430   \n",
      "997  filter_CNN_2D_faultD_2025-05-06-04-23-15_fold1            140.366331   \n",
      "959  filter_CNN_2D_faultD_2025-05-06-04-23-15_fold2            130.508236   \n",
      "998  filter_CNN_2D_faultD_2025-05-06-04-23-15_fold3            136.613893   \n",
      "996  filter_CNN_2D_faultD_2025-05-06-04-23-15_fold4            135.407519   \n",
      "957  filter_CNN_2D_faultD_2025-05-06-04-23-15_fold5            128.432781   \n",
      "896        poisson_faultD_2025-05-06-15-47-30_fold1             88.079848   \n",
      "290        poisson_faultD_2025-05-06-15-47-30_fold2             28.765947   \n",
      "15         poisson_faultD_2025-05-06-15-47-30_fold3              1.448529   \n",
      "65         poisson_faultD_2025-05-06-15-47-30_fold4              6.331916   \n",
      "216        poisson_faultD_2025-05-06-15-47-30_fold5             21.168907   \n",
      "930          TP_2D_faultD_2025-05-06-23-59-05_fold1           3411.408009   \n",
      "0            TP_2D_faultD_2025-05-06-23-59-05_fold2              4.028555   \n",
      "0            TP_2D_faultD_2025-05-06-23-59-05_fold3              3.563812   \n",
      "0            TP_2D_faultD_2025-05-06-23-59-05_fold4              3.527567   \n",
      "0            TP_2D_faultD_2025-05-06-23-59-05_fold5              3.974491   \n",
      "\n",
      "     minute per epoch  \n",
      "12           1.143767  \n",
      "10           1.148571  \n",
      "12           0.537586  \n",
      "2            0.437961  \n",
      "742          0.441223  \n",
      "997          0.140789  \n",
      "959          0.136088  \n",
      "998          0.136888  \n",
      "996          0.135951  \n",
      "957          0.134204  \n",
      "896          0.098303  \n",
      "290          0.099193  \n",
      "15           0.096569  \n",
      "65           0.097414  \n",
      "216          0.098004  \n",
      "930          3.668181  \n",
      "0            4.028555  \n",
      "0            3.563812  \n",
      "0            3.527567  \n",
      "0            3.974491  \n"
     ]
    }
   ],
   "source": [
    "# 병합된 데이터 저장용 리스트\n",
    "highest_rows = []\n",
    "\n",
    "for dir_path in tensorboard_dirs: # 각 로그마다\n",
    "    print(f\"Processing TensorBoard log: {dir_path}\")\n",
    "    ea = event_accumulator.EventAccumulator(dir_path)\n",
    "    ea.Reload() # 텐서보드 로그 뽑아서 변수에 넣기기\n",
    "    \n",
    "    data = {} # 수집된 데이터를 저장할 딕셔너리\n",
    "    epoch_time_map = {}  # 에포크와 wall_time 매핑\n",
    "\n",
    "    # 태그(메트릭) 별로 에포크와 값 빼내서 저장\n",
    "    for tag in tags:\n",
    "        if tag in ea.Tags()[\"scalars\"]:  # 태그가 존재하는지 확인\n",
    "            events = ea.Scalars(tag)\n",
    "            data[tag] = {\n",
    "                \"epoch\": [event.step for event in events],  # step을 epoch으로 사용\n",
    "                \"value\": [event.value for event in events],\n",
    "            }\n",
    "            # epoch -> wall_time 매핑 (처음 태그에서만 추출)\n",
    "            if not epoch_time_map:\n",
    "                epoch_time_map = {event.step: event.wall_time for event in events}\n",
    "        else:\n",
    "            print(f\"Tag '{tag}' not found in the TensorBoard logs.\")\n",
    "\n",
    "    # 태그별 데이터프레임 생성\n",
    "    dataframes = {tag: pd.DataFrame(values) for tag, values in data.items()}\n",
    "\n",
    "    # 단일 데이터프레임으로 병합 (Epoch 기준)\n",
    "    merged_df = pd.DataFrame({\"epoch\": dataframes[tags[0]][\"epoch\"]})  # 첫 태그의 epoch 사용\n",
    "    for tag in tags:\n",
    "        if tag in dataframes:\n",
    "            merged_df[tag] = dataframes[tag][\"value\"]\n",
    "\n",
    "    # 필요한 태그로 필터링\n",
    "    filtered_df = merged_df[['epoch'] + [tag for tag in usable_tags if tag in merged_df.columns]] # 에포크도 보고 싶으니 추가\n",
    "\n",
    "    # 가장 높은 AUROC 값을 갖는 행 추출\n",
    "    if \"valid_AUROC_macro\" in filtered_df.columns:\n",
    "        highest_row = filtered_df.loc[filtered_df['valid_AUROC_macro'].idxmax()].copy()  # 명시적 복사\n",
    "        highest_row[\"source_dir\"] = dir_path.split('/')[-1]  # 로그 출처 추가\n",
    "\n",
    "        # 학습 시간 계산\n",
    "        highest_epoch = int(highest_row['epoch'])\n",
    "        # print(highest_epoch) # 확인 필요\n",
    "\n",
    "        # 최고 에포크가 0으로 나오는 경우는 편의상 1로 계산..\n",
    "        if highest_epoch == 0 : \n",
    "            print(\"최고 에포크 0, 편의상 1로 변경\")\n",
    "            highest_epoch = 1\n",
    "        if highest_row['epoch'] == 0 : \n",
    "            print(\"최고 에포크 0, 편의상 1로 변경\")\n",
    "            highest_row['epoch'] = 1\n",
    "\n",
    "        if highest_epoch in epoch_time_map:\n",
    "            start_time = min(epoch_time_map.values())  # 첫 epoch 시작 시간\n",
    "            end_time = epoch_time_map[highest_epoch]  # 최고 성능 epoch의 시간\n",
    "            elapsed_time = (end_time - start_time) / 60 # 경과 시간 계산 (분)\n",
    "            highest_row[\"total elapsed minute\"] = elapsed_time\n",
    "            highest_row[\"minute per epoch\"] = elapsed_time / highest_row['epoch']\n",
    "        else:\n",
    "            highest_row[\"total elapsed minute\"] = None\n",
    "            highest_row[\"minute per epoch\"] = None  # 해당 에포크 시간 데이터 없음\n",
    "\n",
    "        highest_rows.append(highest_row)\n",
    "\n",
    "# 최종 병합\n",
    "final_df = pd.DataFrame(highest_rows)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\nFinal DataFrame with Highest AUROC Rows:\")\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장하기\n",
    "final_df.to_csv(output_file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_encoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
