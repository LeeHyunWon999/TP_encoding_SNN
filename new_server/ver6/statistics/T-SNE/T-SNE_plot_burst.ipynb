{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-SNE 플롯 찍기용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 변수\n",
    "checkpoint_dir = \"/home/hschoi/data/leehyunwon/ECG-SNN/SNN_MLP_ver6_burst_2024-12-27-13-02-29_fold1_lastEpoch.pt\"\n",
    "config_json_dir = \"/home/hschoi/data/leehyunwon/ECG-SNN/SNN_MLP_ver6_burst_2024-12-27-13-02-29_fold1_config.json\"\n",
    "\n",
    "savefile_name = \"T-SNE_burst.svg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 22:06:42.809495: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-19 22:06:42.863262: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-19 22:06:43.637350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np # .npy 읽기용\n",
    "import pandas as pd # csv 읽기용\n",
    "import torch.nn.functional as F  # 일부 활성화 함수 등 파라미터 없는 함수에 사용\n",
    "import torchvision.datasets as datasets  # 일반적인 데이터셋; 이거 아마 MIT-BIH로 바꿔야 할 듯?\n",
    "import torchvision.transforms as transforms  # 데이터 증강을 위한 일종의 변형작업이라 함\n",
    "from torch import optim  # SGD, Adam 등의 옵티마이저(그래디언트는 이쪽으로 가면 됩니다)\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR # 코사인스케줄러(옵티마이저 보조용)\n",
    "from torch import nn, Tensor  # 모든 DNN 모델들\n",
    "from torch.utils.data import (DataLoader, Dataset)  # 미니배치 등의 데이터셋 관리를 도와주는 녀석\n",
    "from tqdm import tqdm  # 진행도 표시용\n",
    "import torchmetrics # 평가지표 로깅용\n",
    "from typing import Callable # 람다식\n",
    "from torch.utils.tensorboard import SummaryWriter # tensorboard 기록용\n",
    "import time # 텐서보드 폴더명에 쓸 시각정보 기록용\n",
    "import random # 랜덤시드 고정용\n",
    "\n",
    "# 여긴 인코더 넣을때 혹시 몰라서 집어넣었음\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 얘는 SNN 학습이니까 당연히 있어야겠지? 특히 SNN 모델을 따로 만드려는 경우엔 뉴런 말고도 넣을 것이 많다.\n",
    "# import spikingjelly.activation_based as jelly\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, surrogate, layer\n",
    "\n",
    "from sklearn.model_selection import KFold # cross-validation용\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json파일 읽기 성공!\n",
      "Device :cuda\n"
     ]
    }
   ],
   "source": [
    "# 환경설정\n",
    "with open(config_json_dir, 'r') as f:\n",
    "    print(\"config.json파일 읽기 성공!\")\n",
    "    json_data = json.load(f)\n",
    "\n",
    "cuda_gpu = json_data['cuda_gpu']\n",
    "model_name = json_data['model_name']\n",
    "num_classes = json_data['num_classes']\n",
    "num_encoders = json_data['num_encoders'] # 편의상 이녀석을 MIT-BIH 길이인 187로 지정하도록 한다.\n",
    "early_stop = json_data['early_stop']\n",
    "early_stop_enable = json_data['early_stop_enable']\n",
    "learning_rate = json_data['init_lr']\n",
    "batch_size = json_data['batch_size']\n",
    "num_epochs = json_data['num_epochs']\n",
    "train_path = json_data['train_path']\n",
    "test_path = json_data['test_path']\n",
    "class_weight = json_data['class_weight']\n",
    "encoder_min = json_data['encoder_min']\n",
    "encoder_max = json_data['encoder_max']\n",
    "hidden_size = json_data['hidden_size']\n",
    "hidden_size_2 = json_data['hidden_size_2']\n",
    "scheduler_tmax = json_data['scheduler_tmax']\n",
    "scheduler_eta_min = json_data['scheduler_eta_min']\n",
    "encoder_requires_grad = json_data['encoder_requires_grad']\n",
    "timestep = json_data['timestep']\n",
    "burst_beta = json_data['burst_beta']\n",
    "burst_init_th = json_data['burst_init_th']\n",
    "random_seed = json_data['random_seed']\n",
    "checkpoint_save = json_data['checkpoint_save']\n",
    "checkpoint_path = json_data['checkpoint_path']\n",
    "threshold_value = json_data['threshold_value']\n",
    "reset_value_residual = json_data['reset_value_residual']\n",
    "need_bias = json_data['need_bias']\n",
    "k_folds = json_data['k_folds']\n",
    "\n",
    "# Cuda 써야겠지?\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # GPU 번호별로 0번부터 나열\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= str(cuda_gpu)  # 상황에 맞춰 변경할 것\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # 연산에 GPU 쓰도록 지정\n",
    "print(\"Device :\" + device) # 확인용\n",
    "# input() # 일시정지용\n",
    "\n",
    "# 랜덤시드 고정\n",
    "seed = random_seed\n",
    "deterministic = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "# 인코딩용 burst 클래스\n",
    "class BURST(nn.Module):\n",
    "    def __init__(self, beta=2, init_th=0.0625, device='cuda') -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.init_th = init_th\n",
    "        self.device = device\n",
    "        \n",
    "    def burst_encode(self, data, t):\n",
    "        if t==0:\n",
    "            self.mem = data.clone().detach().to(self.device) # 이건 그대로\n",
    "            self.th = torch.ones(self.mem.shape, device=self.device) * self.init_th # 밖에 있는 코드 가져오느라 이렇게 된듯\n",
    "            \n",
    "        self.output = torch.zeros(self.mem.shape).to(self.device) # 0, 1 단위로 보내기 위해 이게 필요(아래 코드에 쓰는 용도)\n",
    "        \n",
    "        fire = (self.mem >= self.th) # 발화여부 확인\n",
    "        self.output = torch.where(fire, torch.ones(self.output.shape, device=self.device), self.output) # 발화됐으면 1, 아니면 0 놓는 녀석\n",
    "        out = torch.where(fire, self.th, torch.zeros(self.mem.shape, device=self.device)) # 얜 이제 잔차로 리셋하는 원래 동작 위해서 있는 녀석\n",
    "        self.mem -= out\n",
    "        \n",
    "        self.th = torch.where(fire, self.th * self.beta, torch.ones(self.th.shape, device=self.device)*self.init_th) # 연속발화시 2배로 늘리기, 아니면 다시 초기치로 이동\n",
    "\n",
    "        # 입력값 재설정하고 싶으면 쓰기 : 원본에서도 이건 그냥 있었으니 냅둘 것\n",
    "        if self.output.max() == 0:\n",
    "            self.mem = data.clone().detach().to(self.device)\n",
    "        \n",
    "        # 반환 : 스파이크 뜬 그 출력용 녀석 내보내기\n",
    "        return self.output.clone().detach()\n",
    "    \n",
    "    def forward(self, input:Tensor, t:int) -> Tensor:\n",
    "        return self.burst_encode(input, t)\n",
    "\n",
    "# 데이터 가져오는 알맹이 클래스\n",
    "class MITLoader_MLP_binary(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transforms: Callable = lambda x: x) -> None:\n",
    "        super().__init__()\n",
    "        self.annotations = pd.read_csv(csv_file).values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotations.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        signal = self.annotations[item, :-1]\n",
    "        signal = torch.from_numpy(signal).float()\n",
    "        if self.transforms : \n",
    "            signal = self.transforms(signal)\n",
    "        \n",
    "        label = int(self.annotations[item, -1])\n",
    "        if label > 0:\n",
    "            label = 1  # 1 이상인 모든 값은 1로 변환(난 이진값 처리하니깐)\n",
    "\n",
    "        return signal, torch.tensor(label).long()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 완료, 시각화중...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# T-SNE 시각화\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m인코딩 완료, 시각화중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mplot_tsne_with_silhouette\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 39\u001b[0m, in \u001b[0;36mplot_tsne_with_silhouette\u001b[0;34m(spike_rates, labels)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_tsne_with_silhouette\u001b[39m(spike_rates, labels):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# T-SNE 변환 수행\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     tsne_results \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_rates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Silhouette Value 계산\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     silhouette_val \u001b[38;5;241m=\u001b[39m silhouette_score(spike_rates, labels)\n",
      "File \u001b[0;32m~/.conda/envs/ecg_encoding/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/ecg_encoding/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ecg_encoding/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:1111\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m-> 1111\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/.conda/envs/ecg_encoding/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:1001\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;66;03m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;66;03m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;66;03m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[1;32m    999\u001b[0m degrees_of_freedom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1001\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tsne\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneighbors_nn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_num_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_num_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ecg_encoding/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:1069\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     opt_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[1;32m   1068\u001b[0m     opt_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_iter_without_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_without_progress\n\u001b[0;32m-> 1069\u001b[0m     params, kl_divergence, it \u001b[38;5;241m=\u001b[39m \u001b[43m_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# Save the final number of iterations\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m it\n",
      "File \u001b[0;32m~/.conda/envs/ecg_encoding/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:402\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# only compute the error when needed\u001b[39;00m\n\u001b[1;32m    400\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m check_convergence \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m n_iter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 402\u001b[0m error, grad \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m inc \u001b[38;5;241m=\u001b[39m update \u001b[38;5;241m*\u001b[39m grad \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    405\u001b[0m dec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minvert(inc)\n",
      "File \u001b[0;32m~/.conda/envs/ecg_encoding/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:279\u001b[0m, in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    276\u001b[0m X_embedded \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mreshape(n_samples, n_components)\n\u001b[1;32m    278\u001b[0m val_P \u001b[38;5;241m=\u001b[39m P\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 279\u001b[0m neighbors \u001b[38;5;241m=\u001b[39m \u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m indptr \u001b[38;5;241m=\u001b[39m P\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    282\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X_embedded\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 모델 로드 함수 정의\n",
    "def load_model(checkpoint_path_, model):\n",
    "    checkpoint = torch.load(checkpoint_path_)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    return model\n",
    "\n",
    "# Spike rate 계산 함수 정의\n",
    "def compute_spike_rate(data_loader):\n",
    "    spike_rates = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            burst_encoder = BURST(beta=burst_beta, init_th=burst_init_th)\n",
    "\n",
    "            # 시간축 반복하여 Spike 계산\n",
    "            spike_sum = torch.zeros(batch_size, num_encoders, device=device)  # 배치와 채널 크기로 초기화\n",
    "            for i in range(timestep):\n",
    "                spikes = burst_encoder(data, i)\n",
    "                spike_sum += spikes\n",
    "\n",
    "            # Spike rate 계산 (스파이크 총합 / 필터 크기)\n",
    "            spike_rate = spike_sum / timestep\n",
    "            spike_rates.append(spike_rate.cpu().numpy())\n",
    "            labels.append(target.cpu().numpy())\n",
    "\n",
    "    spike_rates = np.concatenate(spike_rates, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return spike_rates, labels\n",
    "\n",
    "# T-SNE 시각화 함수 정의(알파 블렌딩 및 Silhouette Value 추가)\n",
    "def plot_tsne_with_silhouette(spike_rates, labels):\n",
    "    # T-SNE 변환 수행\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(spike_rates)\n",
    "\n",
    "    # Silhouette Value 계산\n",
    "    silhouette_val = silhouette_score(spike_rates, labels)\n",
    "\n",
    "    # 그래프 생성\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(\n",
    "        tsne_results[:, 0], tsne_results[:, 1], \n",
    "        c=labels, cmap='tab10', alpha=0.6  # 알파 블렌딩 적용\n",
    "    )\n",
    "\n",
    "    # 컬러바 추가\n",
    "    plt.colorbar(scatter, label='Class Labels')\n",
    "\n",
    "    # 그래프 제목과 라벨 설정\n",
    "    plt.title(f'T-SNE Visualization of Spike Rates\\nSilhouette Value: {silhouette_val:.2f}', fontsize=14)\n",
    "    plt.xlabel('T-SNE Component 1')\n",
    "    plt.ylabel('T-SNE Component 2')\n",
    "\n",
    "    # 그래프 저장\n",
    "    plt.savefig(savefile_name, format=\"svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    # 그래프 표시\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 모델, 로더 지정\n",
    "dataset = MITLoader_MLP_binary(csv_file=test_path)\n",
    "data_loader = DataLoader(dataset, batch_size=256, shuffle=True, drop_last = True)\n",
    "\n",
    "# 스파이크 레이트 계산\n",
    "spike_rates, labels = compute_spike_rate(data_loader)\n",
    "\n",
    "# T-SNE 시각화\n",
    "print(\"인코딩 완료, 시각화중...\")\n",
    "plot_tsne_with_silhouette(spike_rates, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.104116045\n"
     ]
    }
   ],
   "source": [
    "# 실루엣값만 따로 보기\n",
    "silhouette_val = silhouette_score(spike_rates, labels)\n",
    "print(silhouette_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_encoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
