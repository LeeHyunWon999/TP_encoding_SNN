{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-SNE 플롯 찍기용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 변수\n",
    "checkpoint_dir = \"/home/hschoi/data/leehyunwon/ECG-SNN/SNN_MLP_ver6_burst_2024-12-27-13-02-29_fold1_lastEpoch.pt\"\n",
    "config_json_dir = \"/home/hschoi/data/leehyunwon/ECG-SNN/SNN_MLP_ver6_burst_2024-12-27-13-02-29_fold1_config.json\"\n",
    "\n",
    "savefile_name = \"T-SNE_burst.svg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 17:05:29.114453: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-26 17:05:29.166688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-26 17:05:29.921340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np # .npy 읽기용\n",
    "import pandas as pd # csv 읽기용\n",
    "import torch.nn.functional as F  # 일부 활성화 함수 등 파라미터 없는 함수에 사용\n",
    "import torchvision.datasets as datasets  # 일반적인 데이터셋; 이거 아마 MIT-BIH로 바꿔야 할 듯?\n",
    "import torchvision.transforms as transforms  # 데이터 증강을 위한 일종의 변형작업이라 함\n",
    "from torch import optim  # SGD, Adam 등의 옵티마이저(그래디언트는 이쪽으로 가면 됩니다)\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR # 코사인스케줄러(옵티마이저 보조용)\n",
    "from torch import nn, Tensor  # 모든 DNN 모델들\n",
    "from torch.utils.data import (DataLoader, Dataset)  # 미니배치 등의 데이터셋 관리를 도와주는 녀석\n",
    "from tqdm import tqdm  # 진행도 표시용\n",
    "import torchmetrics # 평가지표 로깅용\n",
    "from typing import Callable # 람다식\n",
    "from torch.utils.tensorboard import SummaryWriter # tensorboard 기록용\n",
    "import time # 텐서보드 폴더명에 쓸 시각정보 기록용\n",
    "import random # 랜덤시드 고정용\n",
    "\n",
    "# 여긴 인코더 넣을때 혹시 몰라서 집어넣었음\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 얘는 SNN 학습이니까 당연히 있어야겠지? 특히 SNN 모델을 따로 만드려는 경우엔 뉴런 말고도 넣을 것이 많다.\n",
    "# import spikingjelly.activation_based as jelly\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, surrogate, layer\n",
    "\n",
    "from sklearn.model_selection import KFold # cross-validation용\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json파일 읽기 성공!\n",
      "Device :cuda\n"
     ]
    }
   ],
   "source": [
    "# 환경설정\n",
    "with open(config_json_dir, 'r') as f:\n",
    "    print(\"config.json파일 읽기 성공!\")\n",
    "    json_data = json.load(f)\n",
    "\n",
    "cuda_gpu = json_data['cuda_gpu']\n",
    "model_name = json_data['model_name']\n",
    "num_classes = json_data['num_classes']\n",
    "num_encoders = json_data['num_encoders'] # 편의상 이녀석을 MIT-BIH 길이인 187로 지정하도록 한다.\n",
    "early_stop = json_data['early_stop']\n",
    "early_stop_enable = json_data['early_stop_enable']\n",
    "learning_rate = json_data['init_lr']\n",
    "batch_size = json_data['batch_size']\n",
    "num_epochs = json_data['num_epochs']\n",
    "train_path = json_data['train_path']\n",
    "test_path = json_data['test_path']\n",
    "class_weight = json_data['class_weight']\n",
    "encoder_min = json_data['encoder_min']\n",
    "encoder_max = json_data['encoder_max']\n",
    "hidden_size = json_data['hidden_size']\n",
    "hidden_size_2 = json_data['hidden_size_2']\n",
    "scheduler_tmax = json_data['scheduler_tmax']\n",
    "scheduler_eta_min = json_data['scheduler_eta_min']\n",
    "encoder_requires_grad = json_data['encoder_requires_grad']\n",
    "timestep = json_data['timestep']\n",
    "burst_beta = json_data['burst_beta']\n",
    "burst_init_th = json_data['burst_init_th']\n",
    "random_seed = json_data['random_seed']\n",
    "checkpoint_save = json_data['checkpoint_save']\n",
    "checkpoint_path = json_data['checkpoint_path']\n",
    "threshold_value = json_data['threshold_value']\n",
    "reset_value_residual = json_data['reset_value_residual']\n",
    "need_bias = json_data['need_bias']\n",
    "k_folds = json_data['k_folds']\n",
    "\n",
    "# Cuda 써야겠지?\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # GPU 번호별로 0번부터 나열\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= str(cuda_gpu)  # 상황에 맞춰 변경할 것\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # 연산에 GPU 쓰도록 지정\n",
    "print(\"Device :\" + device) # 확인용\n",
    "# input() # 일시정지용\n",
    "\n",
    "# 랜덤시드 고정\n",
    "seed = random_seed\n",
    "deterministic = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "# 인코딩용 burst 클래스\n",
    "class BURST(nn.Module):\n",
    "    def __init__(self, beta=2, init_th=0.0625, device='cuda') -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.init_th = init_th\n",
    "        self.device = device\n",
    "        \n",
    "    def burst_encode(self, data, t):\n",
    "        if t==0:\n",
    "            self.mem = data.clone().detach().to(self.device) # 이건 그대로\n",
    "            self.th = torch.ones(self.mem.shape, device=self.device) * self.init_th # 밖에 있는 코드 가져오느라 이렇게 된듯\n",
    "            \n",
    "        self.output = torch.zeros(self.mem.shape).to(self.device) # 0, 1 단위로 보내기 위해 이게 필요(아래 코드에 쓰는 용도)\n",
    "        \n",
    "        fire = (self.mem >= self.th) # 발화여부 확인\n",
    "        self.output = torch.where(fire, torch.ones(self.output.shape, device=self.device), self.output) # 발화됐으면 1, 아니면 0 놓는 녀석\n",
    "        out = torch.where(fire, self.th, torch.zeros(self.mem.shape, device=self.device)) # 얜 이제 잔차로 리셋하는 원래 동작 위해서 있는 녀석\n",
    "        self.mem -= out\n",
    "        \n",
    "        self.th = torch.where(fire, self.th * self.beta, torch.ones(self.th.shape, device=self.device)*self.init_th) # 연속발화시 2배로 늘리기, 아니면 다시 초기치로 이동\n",
    "\n",
    "        # 입력값 재설정하고 싶으면 쓰기 : 원본에서도 이건 그냥 있었으니 냅둘 것\n",
    "        if self.output.max() == 0:\n",
    "            self.mem = data.clone().detach().to(self.device)\n",
    "        \n",
    "        # 반환 : 스파이크 뜬 그 출력용 녀석 내보내기\n",
    "        return self.output.clone().detach()\n",
    "    \n",
    "    def forward(self, input:Tensor, t:int) -> Tensor:\n",
    "        return self.burst_encode(input, t)\n",
    "\n",
    "# 데이터 가져오는 알맹이 클래스\n",
    "class MITLoader_MLP_binary(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transforms: Callable = lambda x: x) -> None:\n",
    "        super().__init__()\n",
    "        self.annotations = pd.read_csv(csv_file).values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotations.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        signal = self.annotations[item, :-1]\n",
    "        signal = torch.from_numpy(signal).float()\n",
    "        if self.transforms : \n",
    "            signal = self.transforms(signal)\n",
    "        \n",
    "        label = int(self.annotations[item, -1])\n",
    "        if label > 0:\n",
    "            label = 1  # 1 이상인 모든 값은 1로 변환(난 이진값 처리하니깐)\n",
    "\n",
    "        return signal, torch.tensor(label).long()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 완료, 시각화중...\n",
      "Saved: T-SNE_burst.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 모델 로드 함수 정의\n",
    "def load_model(checkpoint_path_, model):\n",
    "    checkpoint = torch.load(checkpoint_path_)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    return model\n",
    "\n",
    "# Spike rate 계산 함수 정의\n",
    "def compute_spike_rate(data_loader):\n",
    "    spike_rates = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            burst_encoder = BURST(beta=burst_beta, init_th=burst_init_th)\n",
    "\n",
    "            # 시간축 반복하여 Spike 계산\n",
    "            spike_sum = torch.zeros(batch_size, num_encoders, device=device)  # 배치와 채널 크기로 초기화\n",
    "            for i in range(timestep):\n",
    "                spikes = burst_encoder(data, i)\n",
    "                spike_sum += spikes\n",
    "\n",
    "            # Spike rate 계산 (스파이크 총합 / 필터 크기)\n",
    "            spike_rate = spike_sum / timestep\n",
    "            spike_rates.append(spike_rate.cpu().numpy())\n",
    "            labels.append(target.cpu().numpy())\n",
    "\n",
    "    spike_rates = np.concatenate(spike_rates, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return spike_rates, labels\n",
    "\n",
    "\n",
    "def plot_tsne_with_silhouette_2(spike_rates, labels, savefile_name):\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(spike_rates)\n",
    "    silhouette_val = silhouette_score(spike_rates, labels)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    scatter = ax.scatter(\n",
    "        tsne_results[:, 0], tsne_results[:, 1], \n",
    "        c=labels, cmap='tab10', alpha=0.6\n",
    "    )\n",
    "\n",
    "    # Silhouette 값 텍스트 삽입 (우측 하단)\n",
    "    ax.text(\n",
    "        0.98, 0.02,\n",
    "        f'Silhouette Value: {silhouette_val:.4f}',\n",
    "        fontsize=16,\n",
    "        transform=ax.transAxes,\n",
    "        ha='right',\n",
    "        va='bottom',\n",
    "        bbox=dict(facecolor='lightgray', alpha=0.5, boxstyle='round,pad=0.3')\n",
    "    )\n",
    "\n",
    "    # 제목, 축 라벨 제거 (눈금과 틱은 유지)\n",
    "    ax.set_title(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "    # 눈금 숫자, 눈금선, 박스는 모두 기본 유지됨\n",
    "    plt.savefig(savefile_name, format=\"svg\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Saved: {savefile_name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 모델, 로더 지정\n",
    "dataset = MITLoader_MLP_binary(csv_file=test_path)\n",
    "data_loader = DataLoader(dataset, batch_size=256, shuffle=True, drop_last = True)\n",
    "\n",
    "# 스파이크 레이트 계산\n",
    "spike_rates, labels = compute_spike_rate(data_loader)\n",
    "\n",
    "# T-SNE 시각화\n",
    "print(\"인코딩 완료, 시각화중...\")\n",
    "plot_tsne_with_silhouette_2(spike_rates, labels,savefile_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.104116045\n"
     ]
    }
   ],
   "source": [
    "# 실루엣값만 따로 보기\n",
    "silhouette_val = silhouette_score(spike_rates, labels)\n",
    "print(silhouette_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_encoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
