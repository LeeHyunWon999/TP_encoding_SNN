{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras conversion code\n",
    "\n",
    "SNN 모델을 저장하되, IF 레이어는 ReLU로 바꿔서 저장하도록 한다. 대신 IF 레이어의 설정값은 따로 찍어서 보내기.\n",
    "pth_to_h5_my_version의 filter CNN 버전, 인코더가 내부에 들어가있으므로 그 이후의 모델 가중치를 따로 저장할 수 있도록 한다.\n",
    "\n",
    "**주의점 : keras version 2.11이 들어간 환경에서 실행할 것! (KIST의 Neu+ 칩 구동환경과 일치시켜야 함)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/data/hongwonseok/ECG-SNN/KIST/MLP/MLP_binary_NO_BatchNorm.pth'\n",
    "\n",
    "path = '/home/hschoi/data/leehyunwon/ECG-SNN/SNN_MLP_ver5_filter_CNN_LIF_3layer_binary_channel1000_hidden1000_encoderGradTrue_early25_lr0.001_threshold1.0_2024_10_29_11_14_10_lastEpoch.pt'\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2240752/3090495766.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 299,\n",
       " 'model_state_dict': OrderedDict([('cnn_encoders.weight',\n",
       "               tensor([[[-2.5867e+00, -1.7425e+00, -2.1379e+00,  ...,  4.1450e-01,\n",
       "                          4.4089e-01,  1.7568e-01]],\n",
       "               \n",
       "                       [[ 1.0223e+00,  4.3495e-01,  4.0459e-01,  ..., -1.0061e-01,\n",
       "                         -1.5723e-02,  6.2172e-01]],\n",
       "               \n",
       "                       [[-1.5526e+01, -1.5310e+01, -1.4806e+01,  ..., -2.3676e+00,\n",
       "                         -2.0556e+00, -1.7144e+00]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-4.3718e+01, -4.3636e+01, -4.3035e+01,  ..., -7.2167e+00,\n",
       "                         -6.0965e+00, -4.8562e+00]],\n",
       "               \n",
       "                       [[-9.5984e+00, -9.7534e+00, -9.2370e+00,  ..., -1.2113e+00,\n",
       "                         -8.3315e-01, -9.0879e-01]],\n",
       "               \n",
       "                       [[-1.6128e+01, -1.6487e+01, -1.5631e+01,  ..., -2.4720e+00,\n",
       "                         -2.2128e+00, -1.8026e+00]]], device='cuda:0')),\n",
       "              ('hidden.0.weight',\n",
       "               tensor([[-7.7588e-01,  5.7307e-01, -5.4228e-03,  ..., -8.7680e-03,\n",
       "                         2.3885e-01, -2.2579e-03],\n",
       "                       [-1.1902e+00, -5.2867e+00, -5.3639e+00,  ...,  1.9194e-02,\n",
       "                        -7.0197e-01, -9.7548e-01],\n",
       "                       [ 1.0580e-02, -4.9229e-01, -3.9028e-02,  ...,  1.4601e-02,\n",
       "                         2.4631e-02,  5.7526e-01],\n",
       "                       ...,\n",
       "                       [-1.8742e-01,  5.6562e-01, -2.1139e-01,  ...,  2.6054e-02,\n",
       "                        -2.2328e-01,  6.8223e-01],\n",
       "                       [-8.8167e-02,  1.0006e+00,  7.0949e-02,  ..., -1.5435e-02,\n",
       "                         1.7349e-01, -2.1451e+00],\n",
       "                       [-1.1337e+00, -4.9442e+00, -4.9448e+00,  ..., -4.9503e-03,\n",
       "                        -6.5877e-01, -9.9632e-01]], device='cuda:0')),\n",
       "              ('hidden_2.0.weight',\n",
       "               tensor([[ 0.0168, -0.0238, -0.0062,  ..., -0.0094,  0.0307, -0.0313],\n",
       "                       [ 0.0043,  0.0231, -0.0083,  ...,  0.0134,  0.0078, -0.0233],\n",
       "                       [ 0.0146,  0.0032, -0.0025,  ..., -0.0109, -0.0059, -0.0026],\n",
       "                       ...,\n",
       "                       [-0.0180, -0.0196,  0.0122,  ..., -0.0051,  0.0031,  0.0212],\n",
       "                       [ 0.0267, -0.0254, -0.0315,  ..., -0.0230,  0.0055, -0.0258],\n",
       "                       [ 0.0268, -0.0147, -0.0128,  ...,  0.0309, -0.0050,  0.0012]],\n",
       "                      device='cuda:0')),\n",
       "              ('layer.0.weight',\n",
       "               tensor([[ 0.4993, -0.0300,  0.5313,  ...,  0.3681,  0.2847, -0.0231],\n",
       "                       [-0.4944, -0.0060, -0.3779,  ..., -0.4444, -0.4303, -0.0105]],\n",
       "                      device='cuda:0'))]),\n",
       " 'optimizer_state_dict': {'state': {0: {'step': tensor(102600.),\n",
       "    'exp_avg': tensor([[[ 1.1461e-04,  1.1306e-04,  1.0229e-04,  ..., -1.8632e-06,\n",
       "              -1.4793e-05, -1.8832e-05]],\n",
       "    \n",
       "            [[-1.5714e-04, -1.6435e-04, -1.6004e-04,  ..., -9.7935e-05,\n",
       "              -1.1452e-04, -1.1030e-04]],\n",
       "    \n",
       "            [[ 1.5689e-06,  1.3333e-06,  1.1126e-06,  ...,  2.4620e-09,\n",
       "               7.8227e-10, -1.0671e-09]],\n",
       "    \n",
       "            ...,\n",
       "    \n",
       "            [[ 3.4135e-07,  2.9333e-07,  2.5093e-07,  ...,  2.3805e-09,\n",
       "               2.0491e-09,  1.7814e-09]],\n",
       "    \n",
       "            [[ 1.6113e-05,  1.4219e-05,  1.2005e-05,  ...,  1.8041e-07,\n",
       "               1.6335e-07,  1.5388e-07]],\n",
       "    \n",
       "            [[ 6.1270e-05,  5.3490e-05,  4.5469e-05,  ...,  5.7573e-07,\n",
       "               5.1797e-07,  4.7945e-07]]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[[6.2255e-08, 6.1129e-08, 5.8047e-08,  ..., 1.2550e-07,\n",
       "              1.2334e-07, 1.1880e-07]],\n",
       "    \n",
       "            [[1.1953e-06, 1.1551e-06, 1.1312e-06,  ..., 1.1089e-06,\n",
       "              1.1460e-06, 1.1715e-06]],\n",
       "    \n",
       "            [[2.7886e-12, 1.9325e-12, 1.3781e-12,  ..., 1.0892e-15,\n",
       "              1.0736e-15, 1.5296e-15]],\n",
       "    \n",
       "            ...,\n",
       "    \n",
       "            [[1.2085e-13, 8.6796e-14, 6.2486e-14,  ..., 5.7213e-18,\n",
       "              4.1846e-18, 4.0161e-18]],\n",
       "    \n",
       "            [[3.6487e-10, 2.6286e-10, 1.8994e-10,  ..., 1.1704e-13,\n",
       "              1.1385e-13, 1.1675e-13]],\n",
       "    \n",
       "            [[4.8186e-09, 3.4555e-09, 2.4923e-09,  ..., 1.0390e-12,\n",
       "              9.7236e-13, 9.8529e-13]]], device='cuda:0')},\n",
       "   1: {'step': tensor(102600.),\n",
       "    'exp_avg': tensor([[ 9.8651e-07,  1.9382e-06,  5.6052e-45,  ..., -5.6052e-45,\n",
       "             -5.6052e-45,  5.6052e-45],\n",
       "            [ 8.6243e-12,  1.1854e-09, -5.6052e-45,  ...,  5.6052e-45,\n",
       "              5.6052e-45, -5.6052e-45],\n",
       "            [ 2.9285e-06, -3.1320e-08,  5.6052e-45,  ..., -5.6052e-45,\n",
       "             -5.6052e-45,  5.6052e-45],\n",
       "            ...,\n",
       "            [ 6.0273e-06, -3.2673e-06,  5.6052e-45,  ..., -5.6052e-45,\n",
       "             -5.6052e-45, -5.6052e-45],\n",
       "            [ 2.0241e-09,  5.7878e-07,  5.6052e-45,  ..., -5.6052e-45,\n",
       "             -5.6052e-45,  5.6052e-45],\n",
       "            [ 7.1902e-12,  1.1147e-09, -5.6052e-45,  ...,  5.6052e-45,\n",
       "              5.6052e-45, -5.6052e-45]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.3544e-10, 7.8929e-10, 1.6677e-27,  ..., 7.0065e-43, 2.6619e-25,\n",
       "             2.3485e-36],\n",
       "            [7.9974e-23, 1.4226e-18, 2.6057e-37,  ..., 7.0065e-43, 1.4245e-37,\n",
       "             7.0065e-43],\n",
       "            [5.1281e-10, 2.1478e-09, 1.8307e-27,  ..., 7.0065e-43, 8.1762e-25,\n",
       "             4.6748e-37],\n",
       "            ...,\n",
       "            [4.2162e-10, 8.9508e-10, 1.2448e-26,  ..., 7.0065e-43, 3.7115e-25,\n",
       "             1.6163e-38],\n",
       "            [3.3335e-17, 7.5612e-11, 1.5104e-27,  ..., 7.0065e-43, 4.4616e-28,\n",
       "             7.5488e-40],\n",
       "            [5.5288e-23, 1.2791e-18, 1.9503e-37,  ..., 7.0065e-43, 9.4539e-38,\n",
       "             7.0065e-43]], device='cuda:0')},\n",
       "   3: {'step': tensor(102600.),\n",
       "    'exp_avg': tensor([[-0.0005,  0.0000, -0.0004,  ..., -0.0004, -0.0005,  0.0000],\n",
       "            [ 0.0001,  0.0000,  0.0001,  ...,  0.0002,  0.0002,  0.0000]],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.1311e-06, 0.0000e+00, 1.1614e-06,  ..., 7.8266e-07, 1.2836e-06,\n",
       "             0.0000e+00],\n",
       "            [1.5148e-06, 0.0000e+00, 1.5373e-06,  ..., 1.0644e-06, 1.8234e-06,\n",
       "             0.0000e+00]], device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 0.001000000000000022,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'initial_lr': 0.001,\n",
       "    'params': [0, 1, 2, 3]}]},\n",
       " 'loss': 0.15517595401581596}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load(path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cnn_encoders.weight',\n",
       "              tensor([[[-2.5867e+00, -1.7425e+00, -2.1379e+00,  ...,  4.1450e-01,\n",
       "                         4.4089e-01,  1.7568e-01]],\n",
       "              \n",
       "                      [[ 1.0223e+00,  4.3495e-01,  4.0459e-01,  ..., -1.0061e-01,\n",
       "                        -1.5723e-02,  6.2172e-01]],\n",
       "              \n",
       "                      [[-1.5526e+01, -1.5310e+01, -1.4806e+01,  ..., -2.3676e+00,\n",
       "                        -2.0556e+00, -1.7144e+00]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-4.3718e+01, -4.3636e+01, -4.3035e+01,  ..., -7.2167e+00,\n",
       "                        -6.0965e+00, -4.8562e+00]],\n",
       "              \n",
       "                      [[-9.5984e+00, -9.7534e+00, -9.2370e+00,  ..., -1.2113e+00,\n",
       "                        -8.3315e-01, -9.0879e-01]],\n",
       "              \n",
       "                      [[-1.6128e+01, -1.6487e+01, -1.5631e+01,  ..., -2.4720e+00,\n",
       "                        -2.2128e+00, -1.8026e+00]]], device='cuda:0')),\n",
       "             ('hidden.0.weight',\n",
       "              tensor([[-7.7588e-01,  5.7307e-01, -5.4228e-03,  ..., -8.7680e-03,\n",
       "                        2.3885e-01, -2.2579e-03],\n",
       "                      [-1.1902e+00, -5.2867e+00, -5.3639e+00,  ...,  1.9194e-02,\n",
       "                       -7.0197e-01, -9.7548e-01],\n",
       "                      [ 1.0580e-02, -4.9229e-01, -3.9028e-02,  ...,  1.4601e-02,\n",
       "                        2.4631e-02,  5.7526e-01],\n",
       "                      ...,\n",
       "                      [-1.8742e-01,  5.6562e-01, -2.1139e-01,  ...,  2.6054e-02,\n",
       "                       -2.2328e-01,  6.8223e-01],\n",
       "                      [-8.8167e-02,  1.0006e+00,  7.0949e-02,  ..., -1.5435e-02,\n",
       "                        1.7349e-01, -2.1451e+00],\n",
       "                      [-1.1337e+00, -4.9442e+00, -4.9448e+00,  ..., -4.9503e-03,\n",
       "                       -6.5877e-01, -9.9632e-01]], device='cuda:0')),\n",
       "             ('hidden_2.0.weight',\n",
       "              tensor([[ 0.0168, -0.0238, -0.0062,  ..., -0.0094,  0.0307, -0.0313],\n",
       "                      [ 0.0043,  0.0231, -0.0083,  ...,  0.0134,  0.0078, -0.0233],\n",
       "                      [ 0.0146,  0.0032, -0.0025,  ..., -0.0109, -0.0059, -0.0026],\n",
       "                      ...,\n",
       "                      [-0.0180, -0.0196,  0.0122,  ..., -0.0051,  0.0031,  0.0212],\n",
       "                      [ 0.0267, -0.0254, -0.0315,  ..., -0.0230,  0.0055, -0.0258],\n",
       "                      [ 0.0268, -0.0147, -0.0128,  ...,  0.0309, -0.0050,  0.0012]],\n",
       "                     device='cuda:0')),\n",
       "             ('layer.0.weight',\n",
       "              tensor([[ 0.4993, -0.0300,  0.5313,  ...,  0.3681,  0.2847, -0.0231],\n",
       "                      [-0.4944, -0.0060, -0.3779,  ..., -0.4444, -0.4303, -0.0105]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = model['model_state_dict']\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('cnn_encoders.weight', tensor([[[-2.5867e+00, -1.7425e+00, -2.1379e+00,  ...,  4.1450e-01,\n",
       "           4.4089e-01,  1.7568e-01]],\n",
       "\n",
       "        [[ 1.0223e+00,  4.3495e-01,  4.0459e-01,  ..., -1.0061e-01,\n",
       "          -1.5723e-02,  6.2172e-01]],\n",
       "\n",
       "        [[-1.5526e+01, -1.5310e+01, -1.4806e+01,  ..., -2.3676e+00,\n",
       "          -2.0556e+00, -1.7144e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-4.3718e+01, -4.3636e+01, -4.3035e+01,  ..., -7.2167e+00,\n",
       "          -6.0965e+00, -4.8562e+00]],\n",
       "\n",
       "        [[-9.5984e+00, -9.7534e+00, -9.2370e+00,  ..., -1.2113e+00,\n",
       "          -8.3315e-01, -9.0879e-01]],\n",
       "\n",
       "        [[-1.6128e+01, -1.6487e+01, -1.5631e+01,  ..., -2.4720e+00,\n",
       "          -2.2128e+00, -1.8026e+00]]], device='cuda:0')), ('hidden.0.weight', tensor([[-7.7588e-01,  5.7307e-01, -5.4228e-03,  ..., -8.7680e-03,\n",
       "          2.3885e-01, -2.2579e-03],\n",
       "        [-1.1902e+00, -5.2867e+00, -5.3639e+00,  ...,  1.9194e-02,\n",
       "         -7.0197e-01, -9.7548e-01],\n",
       "        [ 1.0580e-02, -4.9229e-01, -3.9028e-02,  ...,  1.4601e-02,\n",
       "          2.4631e-02,  5.7526e-01],\n",
       "        ...,\n",
       "        [-1.8742e-01,  5.6562e-01, -2.1139e-01,  ...,  2.6054e-02,\n",
       "         -2.2328e-01,  6.8223e-01],\n",
       "        [-8.8167e-02,  1.0006e+00,  7.0949e-02,  ..., -1.5435e-02,\n",
       "          1.7349e-01, -2.1451e+00],\n",
       "        [-1.1337e+00, -4.9442e+00, -4.9448e+00,  ..., -4.9503e-03,\n",
       "         -6.5877e-01, -9.9632e-01]], device='cuda:0')), ('hidden_2.0.weight', tensor([[ 0.0168, -0.0238, -0.0062,  ..., -0.0094,  0.0307, -0.0313],\n",
       "        [ 0.0043,  0.0231, -0.0083,  ...,  0.0134,  0.0078, -0.0233],\n",
       "        [ 0.0146,  0.0032, -0.0025,  ..., -0.0109, -0.0059, -0.0026],\n",
       "        ...,\n",
       "        [-0.0180, -0.0196,  0.0122,  ..., -0.0051,  0.0031,  0.0212],\n",
       "        [ 0.0267, -0.0254, -0.0315,  ..., -0.0230,  0.0055, -0.0258],\n",
       "        [ 0.0268, -0.0147, -0.0128,  ...,  0.0309, -0.0050,  0.0012]],\n",
       "       device='cuda:0')), ('layer.0.weight', tensor([[ 0.4993, -0.0300,  0.5313,  ...,  0.3681,  0.2847, -0.0231],\n",
       "        [-0.4944, -0.0060, -0.3779,  ..., -0.4444, -0.4303, -0.0105]],\n",
       "       device='cuda:0'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape 확인\n",
    "filter CNN의 hidden 레이어가 어떻게 생겨먹었는지 알 필요가 있을 것이다. 첫 hidden 레이어의 입력 크기를 그에 맞춰야 하기 때문."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_weights = {k: v.cpu().numpy() for k, v in weight.items()}\n",
    "temp_weights['hidden.0.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Dropout, InputLayer\n",
    "from tensorflow.keras.layers import ZeroPadding1D, Conv1D, BatchNormalization, ReLU, AveragePooling1D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 GPT에게 변환 코드 예시를 받아놨으니 그걸로 진행해보자.\n",
    "\n",
    "**KIST용으로 바꿀 땐 hidden layer 뉴런 수가 1000개 임에 주의!!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1000)              1000000   \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2000      \n",
      "                                                                 \n",
      " output_relu (ReLU)          (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,002,000\n",
      "Trainable params: 1,002,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, ReLU\n",
    "\n",
    "def create_keras_model_SNN(num_classes, num_encoders, hidden_size, hidden_size_2):\n",
    "    # 입력 레이어 정의\n",
    "    inputs = Input(shape=(num_encoders,), name='input')\n",
    "    \n",
    "    # 첫 번째 히든 레이어\n",
    "    x = Dense(hidden_size, use_bias=False, name='hidden1')(inputs)\n",
    "    x = ReLU(name='relu1')(x)\n",
    "    \n",
    "    # 히든레이어 하나만 써서 학습하는 모델로 변경\n",
    "    # # 두 번째 히든 레이어\n",
    "    # x = Dense(hidden_size_2, use_bias=False, name='hidden2')(x)\n",
    "    # x = ReLU(name='relu2')(x)\n",
    "    \n",
    "    # 출력 레이어\n",
    "    predictions = Dense(num_classes, use_bias=False, name='output')(x)\n",
    "    predictions = ReLU(name='output_relu')(predictions)  # IFNode를 ReLU로 치환\n",
    "\n",
    "    # 모델 생성\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 모델 생성 예시\n",
    "keras_model = create_keras_model_SNN(num_classes=2, num_encoders=1000, hidden_size=1000, hidden_size_2=1000) # 필터 인코더 제외한 hidden의 시작 부분도 1000이다.\n",
    "\n",
    "# 모델 구조 확인\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input\n",
      "Layer: hidden1\n",
      "[[-0.05057826 -0.05207479  0.05153325 ... -0.05238639 -0.01452087\n",
      "  -0.00053141]\n",
      " [-0.02624729 -0.00825414 -0.03428898 ...  0.00789499  0.00030709\n",
      "  -0.00209925]\n",
      " [ 0.02744946 -0.00081627 -0.0542388  ...  0.02679453  0.04299771\n",
      "  -0.03263053]\n",
      " ...\n",
      " [ 0.00168516  0.02037694  0.04997388 ... -0.04673339 -0.03101406\n",
      "  -0.01109533]\n",
      " [ 0.02157476 -0.03751058  0.03493372 ...  0.03758385  0.00080955\n",
      "   0.04368544]\n",
      " [ 0.04831579 -0.05065305 -0.05235521 ...  0.0129432  -0.03955241\n",
      "   0.02133524]]\n",
      "Layer: relu1\n",
      "Layer: output\n",
      "[[ 0.07435356 -0.04402163]\n",
      " [ 0.02818016  0.00764083]\n",
      " [ 0.03053914 -0.03700504]\n",
      " ...\n",
      " [-0.06837261 -0.0223956 ]\n",
      " [-0.06721395 -0.00777108]\n",
      " [-0.06685384  0.02789634]]\n",
      "Layer: output_relu\n"
     ]
    }
   ],
   "source": [
    "# keras 모델의 초기 가중치 확인\n",
    "for layer in keras_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for temp_weight in weights:\n",
    "        print(temp_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 추출하고 케라스 모델에 대입하기\n",
    "\n",
    "왜인진 모르겠지만 cuda 커널 이미지가 안맞는다 하다가 또 된다고 하다가 그런다. 일단 시도해서 될 때 계속 진행하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "11.8\n",
      "True\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1000)              1000000   \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2000      \n",
      "                                                                 \n",
      " output_relu (ReLU)          (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,002,000\n",
      "Trainable params: 1,002,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # PyTorch 버전 확인\n",
    "print(torch.version.cuda)  # CUDA 버전 확인\n",
    "print(torch.cuda.is_available())  # CUDA 사용 가능 여부 확인\n",
    "\n",
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "# PyTorch에서 가중치 추출 및 Keras에 적용\n",
    "pt_weights = {k: v.cpu().numpy() for k, v in weight.items()}\n",
    "\n",
    "# Keras 가중치 설정\n",
    "# pytorch의 모델 가중치는 (출력, 입력) 순서로 저장되고 케라스는 그 반대이므로 Transpose 필요\n",
    "keras_model.get_layer('hidden1').set_weights([pt_weights['hidden.0.weight'].T]) # bias 빼기!\n",
    "# keras_model.get_layer('hidden2').set_weights([pt_weights['hidden2.0.weight'].T]) # 레이어 1개만 사용하는 경우 빼야 함!\n",
    "keras_model.get_layer('output').set_weights([pt_weights['layer.0.weight'].T])\n",
    "\n",
    "# 잘 들어갔나 확인?\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "keras_model.save('filterCNN_1000_LIF.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input\n",
      "Layer: hidden1\n",
      "[[-7.75878429e-01 -1.19023597e+00  1.05803665e-02 ... -1.87419534e-01\n",
      "  -8.81674588e-02 -1.13365781e+00]\n",
      " [ 5.73069751e-01 -5.28673029e+00 -4.92291212e-01 ...  5.65622747e-01\n",
      "   1.00063050e+00 -4.94418430e+00]\n",
      " [-5.42276213e-03 -5.36391163e+00 -3.90276350e-02 ... -2.11385891e-01\n",
      "   7.09488168e-02 -4.94481707e+00]\n",
      " ...\n",
      " [-8.76797549e-03  1.91937704e-02  1.46009056e-02 ...  2.60544308e-02\n",
      "  -1.54353362e-02 -4.95032873e-03]\n",
      " [ 2.38846213e-01 -7.01967180e-01  2.46308967e-02 ... -2.23279506e-01\n",
      "   1.73493788e-01 -6.58773601e-01]\n",
      " [-2.25789729e-03 -9.75476086e-01  5.75257778e-01 ...  6.82233632e-01\n",
      "  -2.14508677e+00 -9.96322691e-01]]\n",
      "Layer: relu1\n",
      "Layer: output\n",
      "[[ 0.49932745 -0.49440542]\n",
      " [-0.03003345 -0.00601534]\n",
      " [ 0.531287   -0.3779337 ]\n",
      " ...\n",
      " [ 0.36814916 -0.4443905 ]\n",
      " [ 0.28471193 -0.43030402]\n",
      " [-0.02311547 -0.01046609]]\n",
      "Layer: output_relu\n"
     ]
    }
   ],
   "source": [
    "# 모델의 가중치 확인\n",
    "for layer in keras_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for temp_weight in weights:\n",
    "        print(temp_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 저장된 모델 로드\n",
    "loaded_model = load_model('/home/hschoi/leehyunwon/ECG-SNN/to_keras_conversion/filterCNN_1000_LIF.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1000)              1000000   \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2000      \n",
      "                                                                 \n",
      " output_relu (ReLU)          (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,002,000\n",
      "Trainable params: 1,002,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input\n",
      "Layer: hidden1\n",
      "[[-7.75878429e-01 -1.19023597e+00  1.05803665e-02 ... -1.87419534e-01\n",
      "  -8.81674588e-02 -1.13365781e+00]\n",
      " [ 5.73069751e-01 -5.28673029e+00 -4.92291212e-01 ...  5.65622747e-01\n",
      "   1.00063050e+00 -4.94418430e+00]\n",
      " [-5.42276213e-03 -5.36391163e+00 -3.90276350e-02 ... -2.11385891e-01\n",
      "   7.09488168e-02 -4.94481707e+00]\n",
      " ...\n",
      " [-8.76797549e-03  1.91937704e-02  1.46009056e-02 ...  2.60544308e-02\n",
      "  -1.54353362e-02 -4.95032873e-03]\n",
      " [ 2.38846213e-01 -7.01967180e-01  2.46308967e-02 ... -2.23279506e-01\n",
      "   1.73493788e-01 -6.58773601e-01]\n",
      " [-2.25789729e-03 -9.75476086e-01  5.75257778e-01 ...  6.82233632e-01\n",
      "  -2.14508677e+00 -9.96322691e-01]]\n",
      "Layer: relu1\n",
      "Layer: output\n",
      "[[ 0.49932745 -0.49440542]\n",
      " [-0.03003345 -0.00601534]\n",
      " [ 0.531287   -0.3779337 ]\n",
      " ...\n",
      " [ 0.36814916 -0.4443905 ]\n",
      " [ 0.28471193 -0.43030402]\n",
      " [-0.02311547 -0.01046609]]\n",
      "Layer: output_relu\n"
     ]
    }
   ],
   "source": [
    "# 로드된 모델의 가중치 확인\n",
    "for layer in loaded_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for temp_weight in weights:\n",
    "        print(temp_weight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_conversion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
