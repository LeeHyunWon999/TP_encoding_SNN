{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras conversion code\n",
    "\n",
    "SNN 모델을 저장하되, IF 레이어는 ReLU로 바꿔서 저장하도록 한다. 대신 IF 레이어의 설정값은 따로 찍어서 보내기.\n",
    "\n",
    "**주의점 : keras version 2.11이 들어간 환경에서 실행할 것! (KIST의 Neu+ 칩 구동환경과 일치시켜야 함)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/data/hongwonseok/ECG-SNN/KIST/MLP/MLP_binary_NO_BatchNorm.pth'\n",
    "\n",
    "path = '/home/hschoi/data/leehyunwon/ECG-SNN/SNN_MLP_ver5_poisson_binary_encoders187_hidden1000_encoderGradTrue_early30_lr0.001_threshold1.0_2024_09_12_05_09_45.pt'\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1043392/3090495766.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 77,\n",
       " 'model_state_dict': OrderedDict([('hidden.0.weight',\n",
       "               tensor([[ 0.0040, -0.0009, -0.0425,  ..., -0.3275, -0.2426, -0.2248],\n",
       "                       [ 0.1707,  0.0413, -0.0375,  ...,  0.2879,  0.2965,  0.2889],\n",
       "                       [ 0.1137, -0.2311,  0.3923,  ..., -0.0815, -0.1050,  0.1395],\n",
       "                       ...,\n",
       "                       [-0.1194, -0.1166,  0.0590,  ..., -0.1376, -0.3000, -0.2818],\n",
       "                       [ 0.0211, -0.0637, -0.0319,  ..., -0.1904, -0.1090, -0.1342],\n",
       "                       [-0.2942, -0.2863, -0.0270,  ..., -0.1909, -0.2733, -0.2999]],\n",
       "                      device='cuda:0')),\n",
       "              ('hidden2.0.weight',\n",
       "               tensor([[-0.1905,  0.1714,  0.0270,  ..., -0.0911, -0.0672, -0.0594],\n",
       "                       [-0.1128, -0.1104,  0.0811,  ..., -0.2276, -0.1677, -0.2854],\n",
       "                       [-0.1174, -0.0169,  0.0102,  ...,  0.0938, -0.0391,  0.2793],\n",
       "                       ...,\n",
       "                       [ 0.0825,  0.1323, -0.2709,  ..., -0.1766,  0.0095,  0.0318],\n",
       "                       [-0.3542, -0.0236, -0.1346,  ...,  0.0059, -0.0203, -0.0101],\n",
       "                       [-0.0099,  0.1985,  0.1302,  ..., -0.1104,  0.0210,  0.0186]],\n",
       "                      device='cuda:0')),\n",
       "              ('layer.0.weight',\n",
       "               tensor([[ 0.0698, -0.1378, -0.2811,  ...,  0.1769, -0.0264,  0.1527],\n",
       "                       [-0.0656,  0.2838,  0.3740,  ..., -0.2219, -0.0045, -0.0882]],\n",
       "                      device='cuda:0'))]),\n",
       " 'optimizer_state_dict': {'state': {0: {'step': tensor(53352.),\n",
       "    'exp_avg': tensor([[-3.4307e-06, -5.8053e-05, -1.7625e-06,  ...,  4.9557e-06,\n",
       "              7.6829e-06,  4.2448e-06],\n",
       "            [ 1.1138e-04,  9.6409e-05,  4.6541e-05,  ...,  3.1768e-05,\n",
       "              6.6917e-05,  1.1578e-04],\n",
       "            [-1.0909e-04, -4.0067e-05, -7.8415e-05,  ..., -2.1089e-06,\n",
       "             -6.1861e-06, -7.7837e-06],\n",
       "            ...,\n",
       "            [ 4.4355e-05, -1.1430e-05, -2.2784e-05,  ..., -2.1585e-07,\n",
       "             -2.8097e-07, -1.8958e-07],\n",
       "            [ 4.4667e-06, -2.9301e-07, -1.0710e-06,  ...,  7.7109e-09,\n",
       "              1.2182e-08,  3.1439e-08],\n",
       "            [-3.5607e-05, -3.9394e-05, -1.8729e-05,  ...,  7.0017e-08,\n",
       "              8.6650e-08,  2.5133e-07]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[2.0726e-06, 1.5249e-06, 4.8398e-07,  ..., 3.0333e-09, 2.8255e-09,\n",
       "             5.7547e-09],\n",
       "            [4.6555e-06, 3.7365e-06, 1.2856e-06,  ..., 4.1226e-09, 1.1320e-08,\n",
       "             2.5165e-08],\n",
       "            [5.3264e-06, 3.6848e-06, 1.0407e-06,  ..., 1.2025e-10, 2.1115e-10,\n",
       "             2.3027e-10],\n",
       "            ...,\n",
       "            [2.3722e-06, 1.6150e-06, 8.3532e-07,  ..., 8.2089e-12, 1.5858e-11,\n",
       "             1.1807e-11],\n",
       "            [4.0265e-08, 2.7953e-08, 9.4894e-09,  ..., 2.6396e-16, 7.7657e-16,\n",
       "             2.2087e-15],\n",
       "            [3.4781e-07, 2.5647e-07, 9.6462e-08,  ..., 1.3773e-13, 2.0832e-13,\n",
       "             3.2885e-13]], device='cuda:0')},\n",
       "   1: {'step': tensor(53352.),\n",
       "    'exp_avg': tensor([[-1.2283e-06,  2.2068e-07, -1.9308e-06,  ...,  5.8960e-07,\n",
       "             -2.2916e-07, -7.6243e-08],\n",
       "            [-4.2090e-06, -4.7694e-10, -5.2463e-06,  ..., -8.4642e-09,\n",
       "              5.0119e-11, -5.3615e-10],\n",
       "            [ 2.5380e-06, -1.8612e-08,  8.8906e-06,  ..., -4.0039e-06,\n",
       "              3.5397e-10, -4.3476e-06],\n",
       "            ...,\n",
       "            [-4.4924e-06,  5.9502e-08,  7.5376e-07,  ...,  9.0994e-07,\n",
       "              1.2023e-07,  4.7986e-06],\n",
       "            [ 1.4104e-10, -5.4858e-13,  1.5039e-10,  ...,  1.6143e-12,\n",
       "             -3.0618e-14, -1.7329e-12],\n",
       "            [-1.3168e-05,  7.6206e-08,  1.1681e-06,  ..., -1.8364e-07,\n",
       "             -1.0414e-07, -9.1164e-09]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.1596e-09, 5.4269e-13, 8.0802e-10,  ..., 5.8668e-11, 9.1702e-12,\n",
       "             4.0151e-11],\n",
       "            [6.6576e-10, 8.1587e-17, 3.4585e-10,  ..., 1.7583e-13, 5.6801e-14,\n",
       "             2.7288e-12],\n",
       "            [9.1535e-09, 1.2674e-13, 1.4131e-08,  ..., 2.6019e-10, 3.4736e-13,\n",
       "             2.5754e-09],\n",
       "            ...,\n",
       "            [5.8002e-09, 7.0858e-13, 1.6180e-09,  ..., 1.1390e-10, 7.1090e-13,\n",
       "             9.3757e-11],\n",
       "            [1.3098e-19, 7.5213e-23, 3.3917e-19,  ..., 1.1463e-20, 5.7498e-22,\n",
       "             3.5524e-20],\n",
       "            [1.5325e-09, 4.5882e-13, 1.4978e-09,  ..., 1.3221e-10, 9.0216e-12,\n",
       "             6.7819e-12]], device='cuda:0')},\n",
       "   2: {'step': tensor(53352.),\n",
       "    'exp_avg': tensor([[ 5.2921e-04,  5.8884e-06,  3.0908e-04,  ...,  1.6957e-04,\n",
       "              0.0000e+00, -1.5184e-05],\n",
       "            [-4.6751e-04, -3.7476e-07, -2.1008e-04,  ..., -2.1514e-04,\n",
       "              0.0000e+00,  9.4436e-05]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.7748e-06, 4.9862e-09, 5.2745e-07,  ..., 1.9735e-07, 0.0000e+00,\n",
       "             1.9608e-07],\n",
       "            [2.4558e-06, 7.4421e-10, 2.5274e-07,  ..., 6.7159e-07, 0.0000e+00,\n",
       "             4.6812e-07]], device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 0.0006579634122156018,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'initial_lr': 0.001,\n",
       "    'params': [0, 1, 2]}]},\n",
       " 'loss': 0.02159832932098567}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load(path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.0.weight',\n",
       "              tensor([[ 0.0040, -0.0009, -0.0425,  ..., -0.3275, -0.2426, -0.2248],\n",
       "                      [ 0.1707,  0.0413, -0.0375,  ...,  0.2879,  0.2965,  0.2889],\n",
       "                      [ 0.1137, -0.2311,  0.3923,  ..., -0.0815, -0.1050,  0.1395],\n",
       "                      ...,\n",
       "                      [-0.1194, -0.1166,  0.0590,  ..., -0.1376, -0.3000, -0.2818],\n",
       "                      [ 0.0211, -0.0637, -0.0319,  ..., -0.1904, -0.1090, -0.1342],\n",
       "                      [-0.2942, -0.2863, -0.0270,  ..., -0.1909, -0.2733, -0.2999]],\n",
       "                     device='cuda:0')),\n",
       "             ('hidden2.0.weight',\n",
       "              tensor([[-0.1905,  0.1714,  0.0270,  ..., -0.0911, -0.0672, -0.0594],\n",
       "                      [-0.1128, -0.1104,  0.0811,  ..., -0.2276, -0.1677, -0.2854],\n",
       "                      [-0.1174, -0.0169,  0.0102,  ...,  0.0938, -0.0391,  0.2793],\n",
       "                      ...,\n",
       "                      [ 0.0825,  0.1323, -0.2709,  ..., -0.1766,  0.0095,  0.0318],\n",
       "                      [-0.3542, -0.0236, -0.1346,  ...,  0.0059, -0.0203, -0.0101],\n",
       "                      [-0.0099,  0.1985,  0.1302,  ..., -0.1104,  0.0210,  0.0186]],\n",
       "                     device='cuda:0')),\n",
       "             ('layer.0.weight',\n",
       "              tensor([[ 0.0698, -0.1378, -0.2811,  ...,  0.1769, -0.0264,  0.1527],\n",
       "                      [-0.0656,  0.2838,  0.3740,  ..., -0.2219, -0.0045, -0.0882]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = model['model_state_dict']\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('hidden.0.weight', tensor([[ 0.0040, -0.0009, -0.0425,  ..., -0.3275, -0.2426, -0.2248],\n",
       "        [ 0.1707,  0.0413, -0.0375,  ...,  0.2879,  0.2965,  0.2889],\n",
       "        [ 0.1137, -0.2311,  0.3923,  ..., -0.0815, -0.1050,  0.1395],\n",
       "        ...,\n",
       "        [-0.1194, -0.1166,  0.0590,  ..., -0.1376, -0.3000, -0.2818],\n",
       "        [ 0.0211, -0.0637, -0.0319,  ..., -0.1904, -0.1090, -0.1342],\n",
       "        [-0.2942, -0.2863, -0.0270,  ..., -0.1909, -0.2733, -0.2999]],\n",
       "       device='cuda:0')), ('hidden2.0.weight', tensor([[-0.1905,  0.1714,  0.0270,  ..., -0.0911, -0.0672, -0.0594],\n",
       "        [-0.1128, -0.1104,  0.0811,  ..., -0.2276, -0.1677, -0.2854],\n",
       "        [-0.1174, -0.0169,  0.0102,  ...,  0.0938, -0.0391,  0.2793],\n",
       "        ...,\n",
       "        [ 0.0825,  0.1323, -0.2709,  ..., -0.1766,  0.0095,  0.0318],\n",
       "        [-0.3542, -0.0236, -0.1346,  ...,  0.0059, -0.0203, -0.0101],\n",
       "        [-0.0099,  0.1985,  0.1302,  ..., -0.1104,  0.0210,  0.0186]],\n",
       "       device='cuda:0')), ('layer.0.weight', tensor([[ 0.0698, -0.1378, -0.2811,  ...,  0.1769, -0.0264,  0.1527],\n",
       "        [-0.0656,  0.2838,  0.3740,  ..., -0.2219, -0.0045, -0.0882]],\n",
       "       device='cuda:0'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 13:22:59.819774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Dropout, InputLayer\n",
    "from tensorflow.keras.layers import ZeroPadding1D, Conv1D, BatchNormalization, ReLU, AveragePooling1D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 GPT에게 변환 코드 예시를 받아놨으니 그걸로 진행해보자.\n",
    "\n",
    "**KIST용으로 바꿀 땐 hidden layer 뉴런 수가 1000개 임에 주의!!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 187)]             0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1000)              187000    \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 1000)              1000000   \n",
      "                                                                 \n",
      " relu2 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2000      \n",
      "                                                                 \n",
      " output_relu (ReLU)          (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,189,000\n",
      "Trainable params: 1,189,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 13:23:13.887350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-21 13:23:13.889626: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, ReLU\n",
    "\n",
    "def create_keras_model_SNN(num_classes, num_encoders, hidden_size, hidden_size_2):\n",
    "    # 입력 레이어 정의\n",
    "    inputs = Input(shape=(num_encoders,), name='input')\n",
    "    \n",
    "    # 첫 번째 히든 레이어\n",
    "    x = Dense(hidden_size, use_bias=False, name='hidden1')(inputs)\n",
    "    x = ReLU(name='relu1')(x)\n",
    "    \n",
    "    # 두 번째 히든 레이어\n",
    "    x = Dense(hidden_size_2, use_bias=False, name='hidden2')(x)\n",
    "    x = ReLU(name='relu2')(x)\n",
    "    \n",
    "    # 출력 레이어\n",
    "    predictions = Dense(num_classes, use_bias=False, name='output')(x)\n",
    "    predictions = ReLU(name='output_relu')(predictions)  # IFNode를 ReLU로 치환\n",
    "\n",
    "    # 모델 생성\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 모델 생성 예시\n",
    "keras_model = create_keras_model_SNN(num_classes=2, num_encoders=187, hidden_size=1000, hidden_size_2=1000)\n",
    "\n",
    "# 모델 구조 확인\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input\n",
      "Layer: hidden1\n",
      "[[ 0.0095159  -0.05676141  0.03539276 ...  0.03231388 -0.00660734\n",
      "   0.02882475]\n",
      " [ 0.06387006 -0.03643147  0.01667152 ...  0.05895834 -0.00420672\n",
      "  -0.02237666]\n",
      " [-0.05385975 -0.02775028  0.04240819 ... -0.04462286 -0.04116959\n",
      "   0.06110394]\n",
      " ...\n",
      " [ 0.04204007  0.06519626  0.06933187 ... -0.00518601 -0.02669459\n",
      "   0.00421657]\n",
      " [-0.0473152  -0.04164889 -0.00700943 ... -0.02882376 -0.05631029\n",
      "  -0.02261633]\n",
      " [ 0.0631455   0.05370882 -0.05063476 ... -0.02089823 -0.00274245\n",
      "   0.02198845]]\n",
      "Layer: relu1\n",
      "Layer: hidden2\n",
      "[[ 0.04048454 -0.02098483  0.04033617 ... -0.00050232  0.01342792\n",
      "   0.0042248 ]\n",
      " [-0.02850785  0.03119313 -0.04730089 ... -0.0303368   0.03534647\n",
      "  -0.0444774 ]\n",
      " [-0.03895711  0.01680782 -0.02572041 ... -0.00478426  0.05097898\n",
      "   0.0334655 ]\n",
      " ...\n",
      " [ 0.0144763  -0.00740987 -0.01950781 ...  0.02024866  0.00944719\n",
      "  -0.01374761]\n",
      " [ 0.01066616  0.00255156 -0.00638023 ...  0.00739679 -0.00836627\n",
      "   0.03962421]\n",
      " [ 0.03094814  0.02654241  0.01509454 ... -0.04816955  0.01891492\n",
      "   0.04934764]]\n",
      "Layer: relu2\n",
      "Layer: output\n",
      "[[ 0.07383971 -0.04611311]\n",
      " [-0.01197053  0.04533167]\n",
      " [ 0.00109846 -0.04950599]\n",
      " ...\n",
      " [-0.00306205 -0.02869746]\n",
      " [ 0.02312223 -0.07274909]\n",
      " [-0.0163551   0.0310531 ]]\n",
      "Layer: output_relu\n"
     ]
    }
   ],
   "source": [
    "# keras 모델의 초기 가중치 확인\n",
    "for layer in keras_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for temp_weight in weights:\n",
    "        print(temp_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 추출하고 케라스 모델에 대입하기\n",
    "\n",
    "왜인진 모르겠지만 cuda 커널 이미지가 안맞는다 하다가 또 된다고 하다가 그런다. 일단 시도해서 될 때 계속 진행하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "11.8\n",
      "True\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 187)]             0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1000)              187000    \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 1000)              1000000   \n",
      "                                                                 \n",
      " relu2 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2000      \n",
      "                                                                 \n",
      " output_relu (ReLU)          (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,189,000\n",
      "Trainable params: 1,189,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # PyTorch 버전 확인\n",
    "print(torch.version.cuda)  # CUDA 버전 확인\n",
    "print(torch.cuda.is_available())  # CUDA 사용 가능 여부 확인\n",
    "\n",
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "# PyTorch에서 가중치 추출 및 Keras에 적용\n",
    "pt_weights = {k: v.cpu().numpy() for k, v in weight.items()}\n",
    "\n",
    "# Keras 가중치 설정\n",
    "# pytorch의 모델 가중치는 (출력, 입력) 순서로 저장되고 케라스는 그 반대이므로 Transpose 필요\n",
    "keras_model.get_layer('hidden1').set_weights([pt_weights['hidden.0.weight'].T]) # bias 빼기!\n",
    "keras_model.get_layer('hidden2').set_weights([pt_weights['hidden2.0.weight'].T])\n",
    "keras_model.get_layer('output').set_weights([pt_weights['layer.0.weight'].T])\n",
    "\n",
    "# 잘 들어갔나 확인?\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "keras_model.save('poisson_1000_version_matched.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input\n",
      "Layer: hidden1\n",
      "[[ 0.0039758   0.17069064  0.1137014  ... -0.11940903  0.02108528\n",
      "  -0.29419443]\n",
      " [-0.00085615  0.04129018 -0.231144   ... -0.11658793 -0.06373633\n",
      "  -0.2862571 ]\n",
      " [-0.04247753 -0.03753598  0.39232624 ...  0.05902185 -0.03188704\n",
      "  -0.02703962]\n",
      " ...\n",
      " [-0.32750648  0.2878689  -0.08154733 ... -0.13757966 -0.19037753\n",
      "  -0.19091678]\n",
      " [-0.24262519  0.2964839  -0.10496032 ... -0.30002898 -0.10897356\n",
      "  -0.27325034]\n",
      " [-0.22482607  0.2889046   0.13953541 ... -0.2817562  -0.13415757\n",
      "  -0.29994297]]\n",
      "Layer: relu1\n",
      "Layer: hidden2\n",
      "[[-0.19049005 -0.11279008 -0.11738281 ...  0.08253149 -0.35417482\n",
      "  -0.00988528]\n",
      " [ 0.1714491  -0.11037464 -0.0169176  ...  0.13234243 -0.02364628\n",
      "   0.19849102]\n",
      " [ 0.02701337  0.08113915  0.0101621  ... -0.27092734 -0.1346003\n",
      "   0.13022648]\n",
      " ...\n",
      " [-0.09109195 -0.22763601  0.09377651 ... -0.17659503  0.00589839\n",
      "  -0.1104063 ]\n",
      " [-0.06717236 -0.16765307 -0.03911991 ...  0.00946819 -0.02032254\n",
      "   0.02100657]\n",
      " [-0.05939457 -0.28542885  0.27932957 ...  0.03182784 -0.0101281\n",
      "   0.01855647]]\n",
      "Layer: relu2\n",
      "Layer: output\n",
      "[[ 0.06984653 -0.06556937]\n",
      " [-0.1378137   0.28377447]\n",
      " [-0.2811073   0.37403262]\n",
      " ...\n",
      " [ 0.1769465  -0.22186296]\n",
      " [-0.0263555  -0.00448761]\n",
      " [ 0.1526652  -0.08822995]]\n",
      "Layer: output_relu\n"
     ]
    }
   ],
   "source": [
    "# 모델의 가중치 확인\n",
    "for layer in keras_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for temp_weight in weights:\n",
    "        print(temp_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 저장된 모델 로드\n",
    "loaded_model = load_model('/home/hschoi/leehyunwon/ECG-SNN/to_keras_conversion/poisson_1000_version_matched.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 187)]             0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1000)              187000    \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 1000)              1000000   \n",
      "                                                                 \n",
      " relu2 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2000      \n",
      "                                                                 \n",
      " output_relu (ReLU)          (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,189,000\n",
      "Trainable params: 1,189,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input\n",
      "Layer: hidden1\n",
      "[[ 0.0039758   0.17069064  0.1137014  ... -0.11940903  0.02108528\n",
      "  -0.29419443]\n",
      " [-0.00085615  0.04129018 -0.231144   ... -0.11658793 -0.06373633\n",
      "  -0.2862571 ]\n",
      " [-0.04247753 -0.03753598  0.39232624 ...  0.05902185 -0.03188704\n",
      "  -0.02703962]\n",
      " ...\n",
      " [-0.32750648  0.2878689  -0.08154733 ... -0.13757966 -0.19037753\n",
      "  -0.19091678]\n",
      " [-0.24262519  0.2964839  -0.10496032 ... -0.30002898 -0.10897356\n",
      "  -0.27325034]\n",
      " [-0.22482607  0.2889046   0.13953541 ... -0.2817562  -0.13415757\n",
      "  -0.29994297]]\n",
      "Layer: relu1\n",
      "Layer: hidden2\n",
      "[[-0.19049005 -0.11279008 -0.11738281 ...  0.08253149 -0.35417482\n",
      "  -0.00988528]\n",
      " [ 0.1714491  -0.11037464 -0.0169176  ...  0.13234243 -0.02364628\n",
      "   0.19849102]\n",
      " [ 0.02701337  0.08113915  0.0101621  ... -0.27092734 -0.1346003\n",
      "   0.13022648]\n",
      " ...\n",
      " [-0.09109195 -0.22763601  0.09377651 ... -0.17659503  0.00589839\n",
      "  -0.1104063 ]\n",
      " [-0.06717236 -0.16765307 -0.03911991 ...  0.00946819 -0.02032254\n",
      "   0.02100657]\n",
      " [-0.05939457 -0.28542885  0.27932957 ...  0.03182784 -0.0101281\n",
      "   0.01855647]]\n",
      "Layer: relu2\n",
      "Layer: output\n",
      "[[ 0.06984653 -0.06556937]\n",
      " [-0.1378137   0.28377447]\n",
      " [-0.2811073   0.37403262]\n",
      " ...\n",
      " [ 0.1769465  -0.22186296]\n",
      " [-0.0263555  -0.00448761]\n",
      " [ 0.1526652  -0.08822995]]\n",
      "Layer: output_relu\n"
     ]
    }
   ],
   "source": [
    "# 로드된 모델의 가중치 확인\n",
    "for layer in loaded_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for temp_weight in weights:\n",
    "        print(temp_weight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECG-SNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
