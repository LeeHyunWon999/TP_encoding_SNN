{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras conversion code\n",
    "\n",
    "SNN 모델을 저장하되, IF 레이어는 ReLU로 바꿔서 저장하도록 한다. 대신 IF 레이어의 설정값은 따로 찍어서 보내기.\n",
    "\n",
    "**주의점 : keras version 2.11이 들어간 환경에서 실행할 것! (KIST의 Neu+ 칩 구동환경과 일치시켜야 함)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/data/hongwonseok/ECG-SNN/KIST/MLP/MLP_binary_NO_BatchNorm.pth'\n",
    "\n",
    "path = '/home/hschoi/data/leehyunwon/ECG-SNN/SNN_MLP_ver5_burst_LIF_ablation_weight_init_binary_encoders187_hidden1000_encoderGradTrue_early25_lr0.001_threshold1.0_2024_11_11_11_51_45_lastEpoch.pt'\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2651445/3090495766.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 249,\n",
       " 'model_state_dict': OrderedDict([('hidden.0.weight',\n",
       "               tensor([[-1.2335e+00,  1.0006e+00, -1.3165e+00,  ..., -4.6863e-01,\n",
       "                         1.3399e+00, -3.5492e-01],\n",
       "                       [-3.0440e-01,  6.2515e-01, -4.6082e-03,  ...,  1.1364e+00,\n",
       "                         6.5021e-01,  1.0002e+00],\n",
       "                       [-3.5139e-01,  6.2409e-01, -1.3010e-01,  ...,  1.1064e+00,\n",
       "                         5.7145e-01,  2.6521e-01],\n",
       "                       ...,\n",
       "                       [-1.2156e+00, -6.4707e+00,  2.4936e-01,  ...,  7.0029e-01,\n",
       "                         8.5925e-01,  9.9398e-01],\n",
       "                       [-3.5535e-01,  7.9070e-01,  1.5011e-01,  ...,  5.7006e-01,\n",
       "                         8.8365e-01,  4.8575e-01],\n",
       "                       [-8.9692e-01,  9.8966e-01, -7.6179e-01,  ...,  8.2405e-01,\n",
       "                        -2.0973e-01,  9.1785e-01]], device='cuda:0')),\n",
       "              ('layer.0.weight',\n",
       "               tensor([[ 0.5333,  0.3770,  0.4447,  ..., -1.1320, -0.0344,  0.4614],\n",
       "                       [-0.1436,  0.4576, -0.2711,  ...,  0.4560,  0.5462,  0.1706]],\n",
       "                      device='cuda:0'))]),\n",
       " 'optimizer_state_dict': {'state': {0: {'step': tensor(85500.),\n",
       "    'exp_avg': tensor([[ 5.2732e-06,  1.5402e-05,  5.7941e-07,  ..., -2.2260e-08,\n",
       "             -4.7594e-09, -3.5769e-09],\n",
       "            [-3.1578e-05, -3.0254e-05, -2.1157e-06,  ..., -2.8812e-09,\n",
       "              1.1860e-10,  1.5136e-10],\n",
       "            [ 2.7170e-05,  2.7431e-05,  1.0377e-05,  ...,  4.5695e-09,\n",
       "              1.7588e-10,  9.7887e-11],\n",
       "            ...,\n",
       "            [-1.4349e-05, -1.5207e-05,  1.1263e-06,  ..., -2.6863e-08,\n",
       "             -1.4461e-09, -8.6591e-10],\n",
       "            [-4.0753e-05, -4.6965e-05, -2.5951e-05,  ..., -2.7135e-08,\n",
       "              9.5590e-10,  8.3071e-10],\n",
       "            [-2.6012e-05, -1.6316e-05, -8.8919e-06,  ..., -1.2835e-11,\n",
       "              6.8302e-11,  2.0740e-10]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[6.5066e-10, 6.5664e-09, 4.7254e-10,  ..., 2.8325e-14, 1.9858e-14,\n",
       "             2.4056e-14],\n",
       "            [6.0500e-09, 1.7106e-08, 3.2374e-09,  ..., 1.6848e-12, 4.8675e-14,\n",
       "             7.2246e-15],\n",
       "            [2.2439e-09, 8.6624e-09, 1.6782e-09,  ..., 6.0446e-13, 1.7813e-13,\n",
       "             2.1454e-14],\n",
       "            ...,\n",
       "            [2.8778e-09, 1.7502e-09, 3.5059e-09,  ..., 5.9365e-13, 1.2237e-14,\n",
       "             1.8252e-14],\n",
       "            [9.6624e-09, 3.3698e-08, 6.5859e-09,  ..., 5.0645e-13, 5.6131e-13,\n",
       "             6.9341e-14],\n",
       "            [7.9781e-10, 5.6460e-09, 4.7381e-10,  ..., 1.6009e-13, 7.0288e-14,\n",
       "             1.6642e-14]], device='cuda:0')},\n",
       "   1: {'step': tensor(85500.),\n",
       "    'exp_avg': tensor([[-0.0002, -0.0002, -0.0002,  ..., -0.0003, -0.0002, -0.0002],\n",
       "            [-0.0005, -0.0007, -0.0005,  ..., -0.0004, -0.0007, -0.0006]],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[4.7151e-06, 4.8913e-06, 4.8127e-06,  ..., 4.8835e-06, 4.7973e-06,\n",
       "             4.7666e-06],\n",
       "            [7.2135e-06, 7.7744e-06, 7.1837e-06,  ..., 6.6035e-06, 7.2435e-06,\n",
       "             7.4413e-06]], device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 0.0010000000000000397,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'initial_lr': 0.001,\n",
       "    'params': [0, 1]}]},\n",
       " 'loss': 0.14561506018919104}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load(path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.0.weight',\n",
       "              tensor([[-1.2335e+00,  1.0006e+00, -1.3165e+00,  ..., -4.6863e-01,\n",
       "                        1.3399e+00, -3.5492e-01],\n",
       "                      [-3.0440e-01,  6.2515e-01, -4.6082e-03,  ...,  1.1364e+00,\n",
       "                        6.5021e-01,  1.0002e+00],\n",
       "                      [-3.5139e-01,  6.2409e-01, -1.3010e-01,  ...,  1.1064e+00,\n",
       "                        5.7145e-01,  2.6521e-01],\n",
       "                      ...,\n",
       "                      [-1.2156e+00, -6.4707e+00,  2.4936e-01,  ...,  7.0029e-01,\n",
       "                        8.5925e-01,  9.9398e-01],\n",
       "                      [-3.5535e-01,  7.9070e-01,  1.5011e-01,  ...,  5.7006e-01,\n",
       "                        8.8365e-01,  4.8575e-01],\n",
       "                      [-8.9692e-01,  9.8966e-01, -7.6179e-01,  ...,  8.2405e-01,\n",
       "                       -2.0973e-01,  9.1785e-01]], device='cuda:0')),\n",
       "             ('layer.0.weight',\n",
       "              tensor([[ 0.5333,  0.3770,  0.4447,  ..., -1.1320, -0.0344,  0.4614],\n",
       "                      [-0.1436,  0.4576, -0.2711,  ...,  0.4560,  0.5462,  0.1706]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = model['model_state_dict']\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('hidden.0.weight', tensor([[-1.2335e+00,  1.0006e+00, -1.3165e+00,  ..., -4.6863e-01,\n",
       "          1.3399e+00, -3.5492e-01],\n",
       "        [-3.0440e-01,  6.2515e-01, -4.6082e-03,  ...,  1.1364e+00,\n",
       "          6.5021e-01,  1.0002e+00],\n",
       "        [-3.5139e-01,  6.2409e-01, -1.3010e-01,  ...,  1.1064e+00,\n",
       "          5.7145e-01,  2.6521e-01],\n",
       "        ...,\n",
       "        [-1.2156e+00, -6.4707e+00,  2.4936e-01,  ...,  7.0029e-01,\n",
       "          8.5925e-01,  9.9398e-01],\n",
       "        [-3.5535e-01,  7.9070e-01,  1.5011e-01,  ...,  5.7006e-01,\n",
       "          8.8365e-01,  4.8575e-01],\n",
       "        [-8.9692e-01,  9.8966e-01, -7.6179e-01,  ...,  8.2405e-01,\n",
       "         -2.0973e-01,  9.1785e-01]], device='cuda:0')), ('layer.0.weight', tensor([[ 0.5333,  0.3770,  0.4447,  ..., -1.1320, -0.0344,  0.4614],\n",
       "        [-0.1436,  0.4576, -0.2711,  ...,  0.4560,  0.5462,  0.1706]],\n",
       "       device='cuda:0'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 08:12:20.004442: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Dropout, InputLayer\n",
    "from tensorflow.keras.layers import ZeroPadding1D, Conv1D, BatchNormalization, ReLU, AveragePooling1D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 GPT에게 변환 코드 예시를 받아놨으니 그걸로 진행해보자.\n",
    "\n",
    "**KIST용으로 바꿀 땐 hidden layer 뉴런 수가 1000개 임에 주의!!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 187)]             0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1000)              187000    \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2000      \n",
      "                                                                 \n",
      " output_relu (ReLU)          (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189,000\n",
      "Trainable params: 189,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 08:12:23.521637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-12 08:12:23.523851: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, ReLU\n",
    "\n",
    "def create_keras_model_SNN(num_classes, num_encoders, hidden_size, hidden_size_2):\n",
    "    # 입력 레이어 정의\n",
    "    inputs = Input(shape=(num_encoders,), name='input')\n",
    "    \n",
    "    # 첫 번째 히든 레이어\n",
    "    x = Dense(hidden_size, use_bias=False, name='hidden1')(inputs)\n",
    "    x = ReLU(name='relu1')(x)\n",
    "    \n",
    "    # 히든레이어 하나만 써서 학습하는 모델로 변경\n",
    "    # # 두 번째 히든 레이어\n",
    "    # x = Dense(hidden_size_2, use_bias=False, name='hidden2')(x)\n",
    "    # x = ReLU(name='relu2')(x)\n",
    "    \n",
    "    # 출력 레이어\n",
    "    predictions = Dense(num_classes, use_bias=False, name='output')(x)\n",
    "    predictions = ReLU(name='output_relu')(predictions)  # IFNode를 ReLU로 치환\n",
    "\n",
    "    # 모델 생성\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 모델 생성 예시\n",
    "keras_model = create_keras_model_SNN(num_classes=2, num_encoders=187, hidden_size=1000, hidden_size_2=1000)\n",
    "\n",
    "# 모델 구조 확인\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input\n",
      "Layer: hidden1\n",
      "[[-0.02640168 -0.01862999 -0.04248649 ...  0.04094818  0.04497937\n",
      "  -0.00355694]\n",
      " [ 0.07005209 -0.05157302 -0.04236779 ... -0.03036854  0.06031157\n",
      "  -0.06110189]\n",
      " [-0.02434105  0.01622068 -0.06306787 ...  0.01027253  0.04068963\n",
      "   0.03689116]\n",
      " ...\n",
      " [-0.03582909 -0.00123322 -0.04037126 ...  0.06367682  0.05938189\n",
      "   0.05599415]\n",
      " [-0.00993795  0.01236603  0.05404988 ...  0.02021772  0.00936847\n",
      "  -0.00843982]\n",
      " [-0.04365204  0.01789551  0.07059816 ...  0.07016075 -0.06468721\n",
      "   0.0449997 ]]\n",
      "Layer: relu1\n",
      "Layer: output\n",
      "[[-0.05283988 -0.06616132]\n",
      " [ 0.01382367 -0.06810138]\n",
      " [-0.06359337 -0.01108982]\n",
      " ...\n",
      " [-0.00786005 -0.01395098]\n",
      " [-0.03391179 -0.04594779]\n",
      " [ 0.0291798  -0.06188346]]\n",
      "Layer: output_relu\n"
     ]
    }
   ],
   "source": [
    "# keras 모델의 초기 가중치 확인\n",
    "for layer in keras_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for temp_weight in weights:\n",
    "        print(temp_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 추출하고 케라스 모델에 대입하기\n",
    "\n",
    "왜인진 모르겠지만 cuda 커널 이미지가 안맞는다 하다가 또 된다고 하다가 그런다. 일단 시도해서 될 때 계속 진행하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "11.8\n",
      "True\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 187)]             0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1000)              187000    \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2000      \n",
      "                                                                 \n",
      " output_relu (ReLU)          (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189,000\n",
      "Trainable params: 189,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # PyTorch 버전 확인\n",
    "print(torch.version.cuda)  # CUDA 버전 확인\n",
    "print(torch.cuda.is_available())  # CUDA 사용 가능 여부 확인\n",
    "\n",
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "# PyTorch에서 가중치 추출 및 Keras에 적용\n",
    "pt_weights = {k: v.cpu().numpy() for k, v in weight.items()}\n",
    "\n",
    "# Keras 가중치 설정\n",
    "# pytorch의 모델 가중치는 (출력, 입력) 순서로 저장되고 케라스는 그 반대이므로 Transpose 필요\n",
    "keras_model.get_layer('hidden1').set_weights([pt_weights['hidden.0.weight'].T]) # bias 빼기!\n",
    "# keras_model.get_layer('hidden2').set_weights([pt_weights['hidden2.0.weight'].T]) # 레이어 1개만 사용하는 경우 빼야 함!\n",
    "keras_model.get_layer('output').set_weights([pt_weights['layer.0.weight'].T])\n",
    "\n",
    "# 잘 들어갔나 확인?\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "keras_model.save('LIF_burst_ablation_weight_init.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input\n",
      "Layer: hidden1\n",
      "[[-1.2335384e+00 -3.0439851e-01 -3.5139421e-01 ... -1.2156482e+00\n",
      "  -3.5534975e-01 -8.9691734e-01]\n",
      " [ 1.0005755e+00  6.2515211e-01  6.2408531e-01 ... -6.4707184e+00\n",
      "   7.9070455e-01  9.8965937e-01]\n",
      " [-1.3164735e+00 -4.6082060e-03 -1.3009831e-01 ...  2.4936076e-01\n",
      "   1.5010883e-01 -7.6179141e-01]\n",
      " ...\n",
      " [-4.6862683e-01  1.1363736e+00  1.1063530e+00 ...  7.0028698e-01\n",
      "   5.7005733e-01  8.2404822e-01]\n",
      " [ 1.3398501e+00  6.5020692e-01  5.7144660e-01 ...  8.5924840e-01\n",
      "   8.8364905e-01 -2.0973453e-01]\n",
      " [-3.5491782e-01  1.0001509e+00  2.6521093e-01 ...  9.9398410e-01\n",
      "   4.8574969e-01  9.1784775e-01]]\n",
      "Layer: relu1\n",
      "Layer: output\n",
      "[[ 0.53328925 -0.14359434]\n",
      " [ 0.37704822  0.4575582 ]\n",
      " [ 0.44472793 -0.27111396]\n",
      " ...\n",
      " [-1.1320201   0.45600694]\n",
      " [-0.03438874  0.546174  ]\n",
      " [ 0.46143353  0.17056121]]\n",
      "Layer: output_relu\n"
     ]
    }
   ],
   "source": [
    "# 모델의 가중치 확인\n",
    "for layer in keras_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for temp_weight in weights:\n",
    "        print(temp_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 저장된 모델 로드\n",
    "loaded_model = load_model('/home/hschoi/leehyunwon/ECG-SNN/to_keras_conversion/LIF_burst_ablation_weight_init.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 187)]             0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 1000)              187000    \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 1000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2000      \n",
      "                                                                 \n",
      " output_relu (ReLU)          (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189,000\n",
      "Trainable params: 189,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input\n",
      "Layer: hidden1\n",
      "[[-1.2335384e+00 -3.0439851e-01 -3.5139421e-01 ... -1.2156482e+00\n",
      "  -3.5534975e-01 -8.9691734e-01]\n",
      " [ 1.0005755e+00  6.2515211e-01  6.2408531e-01 ... -6.4707184e+00\n",
      "   7.9070455e-01  9.8965937e-01]\n",
      " [-1.3164735e+00 -4.6082060e-03 -1.3009831e-01 ...  2.4936076e-01\n",
      "   1.5010883e-01 -7.6179141e-01]\n",
      " ...\n",
      " [-4.6862683e-01  1.1363736e+00  1.1063530e+00 ...  7.0028698e-01\n",
      "   5.7005733e-01  8.2404822e-01]\n",
      " [ 1.3398501e+00  6.5020692e-01  5.7144660e-01 ...  8.5924840e-01\n",
      "   8.8364905e-01 -2.0973453e-01]\n",
      " [-3.5491782e-01  1.0001509e+00  2.6521093e-01 ...  9.9398410e-01\n",
      "   4.8574969e-01  9.1784775e-01]]\n",
      "Layer: relu1\n",
      "Layer: output\n",
      "[[ 0.53328925 -0.14359434]\n",
      " [ 0.37704822  0.4575582 ]\n",
      " [ 0.44472793 -0.27111396]\n",
      " ...\n",
      " [-1.1320201   0.45600694]\n",
      " [-0.03438874  0.546174  ]\n",
      " [ 0.46143353  0.17056121]]\n",
      "Layer: output_relu\n"
     ]
    }
   ],
   "source": [
    "# 로드된 모델의 가중치 확인\n",
    "for layer in loaded_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for temp_weight in weights:\n",
    "        print(temp_weight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_conversion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
